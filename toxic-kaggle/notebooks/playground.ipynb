{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.sparse import hstack\n",
    "from scipy.special import logit, expit\n",
    "import string\n",
    "import re    #for regex\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from nltk import pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer   \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import collections\n",
    "import re\n",
    "import sys\n",
    "import pickle\n",
    "import spacy\n",
    "import enchant\n",
    "import gensim\n",
    "import operator\n",
    "import sys, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/\"\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "d = enchant.Dict(\"en_US\")\n",
    "nlp = spacy.load('en')\n",
    "eng_stopwords = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_PATH + 'raw/train.csv').fillna(' ')\n",
    "test = pd.read_csv(DATA_PATH + 'raw/test.csv').fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "all_text = pd.concat([train_text, test_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0005c987bdfc9d4b</td>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0007e25b2121310b</td>\n",
       "      <td>Bye! \\n\\nDon't look, come or think of comming ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>001810bf8c45bf5f</td>\n",
       "      <td>You are gay or antisemmitian? \\n\\nArchangel WH...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>00190820581d90ce</td>\n",
       "      <td>FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                       comment_text  \\\n",
       "6   0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n",
       "12  0005c987bdfc9d4b  Hey... what is it..\\n@ | talk .\\nWhat is it......   \n",
       "16  0007e25b2121310b  Bye! \\n\\nDon't look, come or think of comming ...   \n",
       "42  001810bf8c45bf5f  You are gay or antisemmitian? \\n\\nArchangel WH...   \n",
       "43  00190820581d90ce           FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!   \n",
       "\n",
       "    toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "6       1             1        1       0       1              0  \n",
       "12      1             0        0       0       0              0  \n",
       "16      1             0        0       0       0              0  \n",
       "42      1             0        1       0       1              1  \n",
       "43      1             0        1       0       1              0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate toxic comments from clean ones:\n",
    "train_toxic = train[(train.toxic == 1) | (train.obscene == 1) | (train.threat == 1) | (train.insult == 1) | (train.identity_hate == 1)]\n",
    "train_toxic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_ethnicity = pickle.load(open(\"../ling_src/words_ethnicity.p\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words_ethnicity(text):\n",
    "    cntr = Counter(text.lower().split())\n",
    "    return np.sum([cntr[word.lower()] for word in words_ethnicity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_ethnicity = list(set(words_ethnicity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "train_toxic['words_ethnicity'] = train_toxic['comment_text'].apply(count_words_ethnicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_gender = pickle.load(open(\"../ling_src/words_gender.p\", 'rb'))\n",
    "words_gender = list(set(words_gender))\n",
    "def count_words_gender(text):\n",
    "    cntr = Counter(text.lower().split())\n",
    "    return np.sum([cntr[word.lower()] for word in words_gender])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "train_toxic['words_gender'] = train_toxic['comment_text'].apply(count_words_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_class = pickle.load(open(\"../ling_src/words_class.p\", 'rb'))\n",
    "words_class = list(set(words_class))\n",
    "def count_words_class(text):\n",
    "    cntr = Counter(text.lower().split())\n",
    "    return np.sum([cntr[word.lower()] for word in words_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "train_toxic['words_class'] = train_toxic['comment_text'].apply(count_words_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_nationality = pickle.load(open(\"../ling_src/words_nationality.p\", 'rb'))\n",
    "words_nationality = list(set(words_nationality))\n",
    "def count_words_nationality(text):\n",
    "    cntr = Counter(text.lower().split())\n",
    "    return np.sum([cntr[word.lower()] for word in words_nationality])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "train_toxic['words_nationality'] = train_toxic['comment_text'].apply(count_words_nationality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_religion = pickle.load(open(\"../ling_src/words_religion.p\", 'rb'))\n",
    "words_religion = list(set(words_religion))\n",
    "def count_words_religion(text):\n",
    "    cntr = Counter(text.lower().split())\n",
    "    return np.sum([cntr[word.lower()] for word in words_religion])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "train_toxic['words_religion'] = train_toxic['comment_text'].apply(count_words_religion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27148"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_toxic['words_gender'].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU U CUNT DAMN YOU'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_toxic.loc[27148]['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words_religion</th>\n",
       "      <th>words_class</th>\n",
       "      <th>words_nationality</th>\n",
       "      <th>words_gender</th>\n",
       "      <th>words_ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16225.000000</td>\n",
       "      <td>16225.000000</td>\n",
       "      <td>16225.000000</td>\n",
       "      <td>16225.00000</td>\n",
       "      <td>16225.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.005116</td>\n",
       "      <td>0.013313</td>\n",
       "      <td>0.15359</td>\n",
       "      <td>0.013313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.027186</td>\n",
       "      <td>0.084036</td>\n",
       "      <td>0.563253</td>\n",
       "      <td>4.01740</td>\n",
       "      <td>0.563253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>312.00000</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       words_religion   words_class  words_nationality  words_gender  \\\n",
       "count    16225.000000  16225.000000       16225.000000   16225.00000   \n",
       "mean         0.000740      0.005116           0.013313       0.15359   \n",
       "std          0.027186      0.084036           0.563253       4.01740   \n",
       "min          0.000000      0.000000           0.000000       0.00000   \n",
       "25%          0.000000      0.000000           0.000000       0.00000   \n",
       "50%          0.000000      0.000000           0.000000       0.00000   \n",
       "75%          0.000000      0.000000           0.000000       0.00000   \n",
       "max          1.000000      5.000000          70.000000     312.00000   \n",
       "\n",
       "       words_ethnicity  \n",
       "count     16225.000000  \n",
       "mean          0.013313  \n",
       "std           0.563253  \n",
       "min           0.000000  \n",
       "25%           0.000000  \n",
       "50%           0.000000  \n",
       "75%           0.000000  \n",
       "max          70.000000  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_toxic[['words_religion', 'words_class',  'words_nationality', 'words_gender', 'words_ethnicity']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['words_gender'] = train['comment_text'].apply(count_words_gender)\n",
    "train['words_religion'] = train['comment_text'].apply(count_words_religion)\n",
    "train['words_nationality'] = train['comment_text'].apply(count_words_nationality)\n",
    "train['words_class'] = train['comment_text'].apply(count_words_class)\n",
    "train['words_ethnicity'] = train['comment_text'].apply(count_words_ethnicity)\n",
    "train.to_csv(DATA_PATH + 'preprocessed/train_hatebase.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['words_gender'] = test['comment_text'].apply(count_words_gender)\n",
    "test['words_religion'] = test['comment_text'].apply(count_words_religion)\n",
    "test['words_nationality'] = test['comment_text'].apply(count_words_nationality)\n",
    "test['words_class'] = test['comment_text'].apply(count_words_class)\n",
    "test['words_ethnicity'] = test['comment_text'].apply(count_words_ethnicity)\n",
    "test.to_csv(DATA_PATH + 'preprocessed/test_hatebase.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
