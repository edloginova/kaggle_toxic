{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import logging\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.optimizers import Adam\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import itertools\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.utils import class_weight\n",
    "from keras.callbacks import *\n",
    "import gensim\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "# set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"../models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bidirectional_lstm_ensemble_per_class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/\"\n",
    "data = pd.read_csv(DATA_PATH + \"preprocessed/train_heavy_clean_no-stopwords.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>heavy_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>' aww ! matches background colour seemingly st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man , really trying edit war . guy constan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\" cannotmake real suggestions improvement - wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>, sir , hero . chance remember page ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                id  \\\n",
       "0           0  0000997932d777bf   \n",
       "1           1  000103f0d9cfb60f   \n",
       "2           2  000113f07ec002fd   \n",
       "3           3  0001b41b1c6bb37e   \n",
       "4           4  0001d958c54c6e35   \n",
       "\n",
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0             0   \n",
       "1  D'aww! He matches this background colour I'm s...      0             0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0             0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0             0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \\\n",
       "0        0       0       0              0   \n",
       "1        0       0       0              0   \n",
       "2        0       0       0              0   \n",
       "3        0       0       0              0   \n",
       "4        0       0       0              0   \n",
       "\n",
       "                                         heavy_clean  \n",
       "0  explanation edits made username hardcore metal...  \n",
       "1  ' aww ! matches background colour seemingly st...  \n",
       "2  hey man , really trying edit war . guy constan...  \n",
       "3  \" cannotmake real suggestions improvement - wo...  \n",
       "4              , sir , hero . chance remember page ?  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[['comment_text', 'heavy_clean']], data[list_classes], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=None, oov_token=0)\n",
    "tokenizer.fit_on_texts(X_train['comment_text'])\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.loc[pd.isnull(X_train['heavy_clean'])]['heavy_clean'] = X_train[pd.isnull(X_train['heavy_clean'])]['comment_text'].apply(heavy_clean)\n",
    "\n",
    "# X_train.loc[8846]['heavy_clean'] = heavy_clean(X_train.loc[8846]['comment_text'])\n",
    "\n",
    "# X_train[pd.isnull(X_train['heavy_clean'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index_w2v = gensim.models.KeyedVectors.load_word2vec_format('../../../embeddings/GoogleNews-vectors-negative300.bin', binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print('Found %s word vectors.' % len(embeddings_index_w2v.vocab))\n",
    "embedding_matrix = np.zeros((len(word_index) + 2, 300))\n",
    "oov = []\n",
    "embedding_matrix[0] = np.random.rand(1, 300)\n",
    "embedding_matrix[-1] = np.zeros((1, 300))\n",
    "for word, i in word_index.items():\n",
    "    word = str(word)\n",
    "    if word in embeddings_index_w2v.vocab:\n",
    "        embedding_vector = embeddings_index_w2v[word]\n",
    "        embedding_matrix[i] = embedding_vector / np.linalg.norm(embedding_vector)\n",
    "    elif word.lower() in embeddings_index_w2v.vocab:\n",
    "        embedding_vector = embeddings_index_w2v[word.lower()]\n",
    "        embedding_matrix[i] = embedding_vector / np.linalg.norm(embedding_vector)\n",
    "    elif word.capitalize() in embeddings_index_w2v.vocab:\n",
    "        embedding_vector = embeddings_index_w2v[word.capitalize()]\n",
    "        embedding_matrix[i] = embedding_vector / np.linalg.norm(embedding_vector)\n",
    "    elif word.lower().capitalize() in embeddings_index_w2v.vocab:\n",
    "        embedding_vector = embeddings_index_w2v[word.lower().capitalize()]\n",
    "        embedding_matrix[i] = embedding_vector / np.linalg.norm(embedding_vector)\n",
    "    else:\n",
    "        oov.append(word)\n",
    "embedding_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164436"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58515"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(word_index) & set(embeddings_index_w2v.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80765"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13909956,  0.49121553,  0.13078724, ...,  0.30649366,\n",
       "         0.39451936,  0.80310854],\n",
       "       [ 0.07468531,  0.09791063,  0.04645062, ...,  0.00341549,\n",
       "         0.04440133, -0.06421115],\n",
       "       [ 0.01803273,  0.0796839 ,  0.03568782, ...,  0.03077838,\n",
       "        -0.01652214, -0.09403456],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.04803049, -0.03817808,  0.03217427, ...,  0.00434891,\n",
       "        -0.0180884 ,  0.08744012],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(embedding_matrix.shape[0],\n",
    "                            embedding_size,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_length, trainable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(clipnorm=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_texts = tokenizer.texts_to_sequences(X_train['comment_text'])\n",
    "x_train_texts = pad_sequences(x_train_texts, maxlen=max_length, padding='post')\n",
    "\n",
    "x_test_texts = tokenizer.texts_to_sequences(X_test['comment_text'])\n",
    "x_test_texts = pad_sequences(x_test_texts, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5527967652868119, 1: 5.235138576045441}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train.values[:, 0]), y_train.values[:, 0])\n",
    "class_weights = {i:x for i, x in enumerate(list(class_weights))}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 300)          49331400  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 200, 40)           51520     \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 10)                1880      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 49,384,811\n",
      "Trainable params: 53,411\n",
      "Non-trainable params: 49,331,400\n",
      "_________________________________________________________________\n",
      "Train on 106912 samples, validate on 52659 samples\n",
      "Epoch 1/3\n",
      "106912/106912 [==============================] - 234s 2ms/step - loss: 0.3327 - acc: 0.8779 - val_loss: 0.2244 - val_acc: 0.9158\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.967579 \n",
      "\n",
      "Epoch 2/3\n",
      "106912/106912 [==============================] - 233s 2ms/step - loss: 0.2371 - acc: 0.9059 - val_loss: 0.1647 - val_acc: 0.9400\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.972477 \n",
      "\n",
      "Epoch 3/3\n",
      "106912/106912 [==============================] - 233s 2ms/step - loss: 0.2094 - acc: 0.9136 - val_loss: 0.1580 - val_acc: 0.9417\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.975143 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe0dd5aba20>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_input = Input(shape=(max_length,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "lstm1 = Bidirectional(CuDNNLSTM(20, return_sequences=True))(embedded_sequences)\n",
    "lstm2 = Bidirectional(CuDNNLSTM(5))(lstm1)\n",
    "output = Dense(units=1, activation='sigmoid')(lstm2)\n",
    "model_1 = Model(sequence_input, output)\n",
    "model_1.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])    \n",
    "model_1.summary()\n",
    "RocAuc = RocAucEvaluation(validation_data=(x_test_texts, y_test), interval=1)\n",
    "model_1.fit(x_train_texts, y_train.values[:, 0], validation_data=(x_test_texts, y_test.values[:, 0]),\n",
    "              epochs=epochs, batch_size=batch_size, callbacks=[RocAuc], class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.505049932447115, 1: 50.005612722170255}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train.values[:, 1]), y_train.values[:, 1])\n",
    "class_weights = {i:x for i, x in enumerate(list(class_weights))}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 300)          49331400  \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 200, 40)           51520     \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 10)                1880      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 49,384,811\n",
      "Trainable params: 53,411\n",
      "Non-trainable params: 49,331,400\n",
      "_________________________________________________________________\n",
      "Train on 106912 samples, validate on 52659 samples\n",
      "Epoch 1/3\n",
      "106912/106912 [==============================] - 234s 2ms/step - loss: 0.2504 - acc: 0.9058 - val_loss: 0.1249 - val_acc: 0.9588\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.908126 \n",
      "\n",
      "Epoch 2/3\n",
      "106912/106912 [==============================] - 233s 2ms/step - loss: 0.1503 - acc: 0.9399 - val_loss: 0.2132 - val_acc: 0.9246\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.936712 \n",
      "\n",
      "Epoch 3/3\n",
      "106912/106912 [==============================] - 233s 2ms/step - loss: 0.1255 - acc: 0.9470 - val_loss: 0.1680 - val_acc: 0.9411\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.919695 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe0bc2cff28>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_input = Input(shape=(max_length,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "lstm1 = Bidirectional(CuDNNLSTM(20, return_sequences=True))(embedded_sequences)\n",
    "lstm2 = Bidirectional(CuDNNLSTM(5))(lstm1)\n",
    "output = Dense(units=1, activation='sigmoid')(lstm2)\n",
    "model_2 = Model(sequence_input, output)\n",
    "model_2.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])    \n",
    "model_2.summary()\n",
    "RocAuc = RocAucEvaluation(validation_data=(x_test_texts, y_test), interval=1)\n",
    "model_2.fit(x_train_texts, y_train.values[:, 1], validation_data=(x_test_texts, y_test.values[:, 1]),\n",
    "              epochs=epochs, batch_size=batch_size, callbacks=[RocAuc], class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5277311588050625, 1: 9.515129939480243}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train.values[:, 2]), y_train.values[:, 2])\n",
    "class_weights = {i:x for i, x in enumerate(list(class_weights))}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 300)          49331400  \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 200, 40)           51520     \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 10)                1880      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 49,384,811\n",
      "Trainable params: 53,411\n",
      "Non-trainable params: 49,331,400\n",
      "_________________________________________________________________\n",
      "Train on 106912 samples, validate on 52659 samples\n",
      "Epoch 1/3\n",
      "106912/106912 [==============================] - 234s 2ms/step - loss: 0.3075 - acc: 0.8734 - val_loss: 0.1467 - val_acc: 0.9499\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.944215 \n",
      "\n",
      "Epoch 2/3\n",
      "106912/106912 [==============================] - 231s 2ms/step - loss: 0.1907 - acc: 0.9327 - val_loss: 0.1397 - val_acc: 0.9567\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.940778 \n",
      "\n",
      "Epoch 3/3\n",
      "106912/106912 [==============================] - 231s 2ms/step - loss: 0.1678 - acc: 0.9335 - val_loss: 0.1681 - val_acc: 0.9536\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.944778 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe07f4dbeb8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_input = Input(shape=(max_length,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "lstm1 = Bidirectional(CuDNNLSTM(20, return_sequences=True))(embedded_sequences)\n",
    "lstm2 = Bidirectional(CuDNNLSTM(5))(lstm1)\n",
    "output = Dense(units=1, activation='sigmoid')(lstm2)\n",
    "model_3 = Model(sequence_input, output)\n",
    "model_3.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])    \n",
    "model_3.summary()\n",
    "RocAuc = RocAucEvaluation(validation_data=(x_test_texts, y_test), interval=1)\n",
    "model_3.fit(x_train_texts, y_train.values[:, 2], validation_data=(x_test_texts, y_test.values[:, 2]),\n",
    "              epochs=epochs, batch_size=batch_size, callbacks=[RocAuc], class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5015292815191489, 1: 163.9754601226994}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train.values[:, 3]), y_train.values[:, 3])\n",
    "class_weights = {i:x for i, x in enumerate(list(class_weights))}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 300)          49331400  \n",
      "_________________________________________________________________\n",
      "bidirectional_9 (Bidirection (None, 200, 40)           51520     \n",
      "_________________________________________________________________\n",
      "bidirectional_10 (Bidirectio (None, 10)                1880      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 49,384,811\n",
      "Trainable params: 53,411\n",
      "Non-trainable params: 49,331,400\n",
      "_________________________________________________________________\n",
      "Train on 106912 samples, validate on 52659 samples\n",
      "Epoch 1/3\n",
      "106912/106912 [==============================] - 231s 2ms/step - loss: 0.4130 - acc: 0.8668 - val_loss: 0.2484 - val_acc: 0.9331\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.857537 \n",
      "\n",
      "Epoch 2/3\n",
      "106912/106912 [==============================] - 230s 2ms/step - loss: 0.2408 - acc: 0.9091 - val_loss: 0.7458 - val_acc: 0.6610\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.818244 \n",
      "\n",
      "Epoch 3/3\n",
      "106912/106912 [==============================] - 229s 2ms/step - loss: 0.2030 - acc: 0.9138 - val_loss: 0.0558 - val_acc: 0.9848\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.863500 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe07718ada0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_input = Input(shape=(max_length,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "lstm1 = Bidirectional(CuDNNLSTM(20, return_sequences=True))(embedded_sequences)\n",
    "lstm2 = Bidirectional(CuDNNLSTM(5))(lstm1)\n",
    "output = Dense(units=1, activation='sigmoid')(lstm2)\n",
    "model_4 = Model(sequence_input, output)\n",
    "model_4.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])    \n",
    "model_4.summary()\n",
    "RocAuc = RocAucEvaluation(validation_data=(x_test_texts, y_test), interval=1)\n",
    "model_4.fit(x_train_texts, y_train.values[:, 3], validation_data=(x_test_texts, y_test.values[:, 3]),\n",
    "              epochs=epochs, batch_size=batch_size, callbacks=[RocAuc], class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5257381144397018, 1: 10.213221245701185}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train.values[:, 4]), y_train.values[:, 4])\n",
    "class_weights = {i:x for i, x in enumerate(list(class_weights))}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 300)          49331400  \n",
      "_________________________________________________________________\n",
      "bidirectional_11 (Bidirectio (None, 200, 40)           51520     \n",
      "_________________________________________________________________\n",
      "bidirectional_12 (Bidirectio (None, 10)                1880      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 49,384,811\n",
      "Trainable params: 53,411\n",
      "Non-trainable params: 49,331,400\n",
      "_________________________________________________________________\n",
      "Train on 106912 samples, validate on 52659 samples\n",
      "Epoch 1/3\n",
      "106912/106912 [==============================] - 233s 2ms/step - loss: 0.3020 - acc: 0.8648 - val_loss: 0.2538 - val_acc: 0.8884\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.954254 \n",
      "\n",
      "Epoch 2/3\n",
      "106912/106912 [==============================] - 232s 2ms/step - loss: 0.1942 - acc: 0.9198 - val_loss: 0.1179 - val_acc: 0.9542\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.955936 \n",
      "\n",
      "Epoch 3/3\n",
      "106912/106912 [==============================] - 233s 2ms/step - loss: 0.1725 - acc: 0.9297 - val_loss: 0.1627 - val_acc: 0.9427\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.965744 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe073dabcc0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_input = Input(shape=(max_length,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "lstm1 = Bidirectional(CuDNNLSTM(20, return_sequences=True))(embedded_sequences)\n",
    "lstm2 = Bidirectional(CuDNNLSTM(5))(lstm1)\n",
    "output = Dense(units=1, activation='sigmoid')(lstm2)\n",
    "model_5 = Model(sequence_input, output)\n",
    "model_5.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])    \n",
    "model_5.summary()\n",
    "RocAuc = RocAucEvaluation(validation_data=(x_test_texts, y_test), interval=1)\n",
    "model_5.fit(x_train_texts, y_train.values[:, 4], validation_data=(x_test_texts, y_test.values[:, 4]),\n",
    "              epochs=epochs, batch_size=batch_size, callbacks=[RocAuc], class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5044065749495178, 1: 57.23340471092077}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train.values[:, 5]), y_train.values[:, 5])\n",
    "class_weights = {i:x for i, x in enumerate(list(class_weights))}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 300)          49331400  \n",
      "_________________________________________________________________\n",
      "bidirectional_13 (Bidirectio (None, 200, 40)           51520     \n",
      "_________________________________________________________________\n",
      "bidirectional_14 (Bidirectio (None, 10)                1880      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 49,384,811\n",
      "Trainable params: 53,411\n",
      "Non-trainable params: 49,331,400\n",
      "_________________________________________________________________\n",
      "Train on 106912 samples, validate on 52659 samples\n",
      "Epoch 1/3\n",
      "106912/106912 [==============================] - 235s 2ms/step - loss: 0.3858 - acc: 0.8299 - val_loss: 0.3672 - val_acc: 0.8734\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.930112 \n",
      "\n",
      "Epoch 2/3\n",
      "106912/106912 [==============================] - 234s 2ms/step - loss: 0.2302 - acc: 0.9165 - val_loss: 0.1312 - val_acc: 0.9541\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.886322 \n",
      "\n",
      "Epoch 3/3\n",
      "106912/106912 [==============================] - 234s 2ms/step - loss: 0.1947 - acc: 0.9162 - val_loss: 0.2172 - val_acc: 0.9205\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.920311 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe07119f898>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_input = Input(shape=(max_length,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "lstm1 = Bidirectional(CuDNNLSTM(20, return_sequences=True))(embedded_sequences)\n",
    "lstm2 = Bidirectional(CuDNNLSTM(5))(lstm1)\n",
    "output = Dense(units=1, activation='sigmoid')(lstm2)\n",
    "model_6 = Model(sequence_input, output)\n",
    "model_6.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])    \n",
    "model_6.summary()\n",
    "RocAuc = RocAucEvaluation(validation_data=(x_test_texts, y_test), interval=1)\n",
    "model_6.fit(x_train_texts, y_train.values[:, 5], validation_data=(x_test_texts, y_test.values[:, 5]),\n",
    "              epochs=epochs, batch_size=batch_size, callbacks=[RocAuc], class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n",
      "Saved model to disk\n",
      "Saved model to disk\n",
      "Saved model to disk\n",
      "Saved model to disk\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model_1.to_json()\n",
    "with open(\"../models/bidirectional_lstm_ensemble_per_class_model_1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_1.save_weights(\"../models/bidirectional_lstm_ensemble_per_class_model_1.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " \n",
    "\n",
    "model_json = model_2.to_json()\n",
    "with open(\"../models/bidirectional_lstm_ensemble_per_class_model_2.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_2.save_weights(\"../models/bidirectional_lstm_ensemble_per_class_model_2.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " \n",
    "\n",
    "model_json = model_3.to_json()\n",
    "with open(\"../models/bidirectional_lstm_ensemble_per_class_model_3.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_3.save_weights(\"../models/bidirectional_lstm_ensemble_per_class_model_3.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " \n",
    "\n",
    "model_json = model_4.to_json()\n",
    "with open(\"../models/bidirectional_lstm_ensemble_per_class_model_4.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_4.save_weights(\"../models/bidirectional_lstm_ensemble_per_class_model_4.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " \n",
    "\n",
    "model_json = model_5.to_json()\n",
    "with open(\"../models/bidirectional_lstm_ensemble_per_class_model_5.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_5.save_weights(\"../models/bidirectional_lstm_ensemble_per_class_model_5.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "model_json = model_6.to_json()\n",
    "with open(\"../models/bidirectional_lstm_ensemble_per_class_model_6.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_6.save_weights(\"../models/bidirectional_lstm_ensemble_per_class_model_6.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 3 but is rank 2 for 'model_1_1/bidirectional_1/Tile' (op: 'Tile') with input shapes: [?,300,1], [2].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    653\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    655\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape must be rank 3 but is rank 2 for 'model_1_1/bidirectional_1/Tile' (op: 'Tile') with input shapes: [?,300,1], [2].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-25e9a57b0f2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcombined_sequence_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcombined_embedded_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_sequence_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m combined_conc = concatenate([model_1(combined_embedded_sequences),\n\u001b[0m\u001b[1;32m      5\u001b[0m              \u001b[0mmodel_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_embedded_sequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m              \u001b[0mmodel_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_embedded_sequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m   2079\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_tensor_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m             \u001b[0moutput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_internal_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mrun_internal_graph\u001b[0;34m(self, inputs, masks)\u001b[0m\n\u001b[1;32m   2230\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0;34m'mask'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m                                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputed_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2232\u001b[0;31m                             \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2233\u001b[0m                             output_masks = _to_list(layer.compute_mask(computed_tensor,\n\u001b[1;32m   2234\u001b[0m                                                                        computed_mask))\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/layers/wrappers.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask, initial_state)\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0my_rev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackward_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0my_rev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/layers/cudnn_recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_initial_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mget_initial_state\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m             return [K.tile(initial_state, [1, dim])\n\u001b[0;32m--> 490\u001b[0;31m                     for dim in self.cell.state_size]\n\u001b[0m\u001b[1;32m    491\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m             return [K.tile(initial_state, [1, dim])\n\u001b[0;32m--> 490\u001b[0;31m                     for dim in self.cell.state_size]\n\u001b[0m\u001b[1;32m    491\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mtile\u001b[0;34m(x, n)\u001b[0m\n\u001b[1;32m   2092\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2093\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2094\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mtile\u001b[0;34m(input, multiples, name)\u001b[0m\n\u001b[1;32m   3845\u001b[0m   \"\"\"\n\u001b[1;32m   3846\u001b[0m   result = _op_def_lib.apply_op(\"Tile\", input=input, multiples=multiples,\n\u001b[0;32m-> 3847\u001b[0;31m                                 name=name)\n\u001b[0m\u001b[1;32m   3848\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    765\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    766\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2630\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2631\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2632\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2633\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2634\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1909\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    593\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    594\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    596\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    657\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape must be rank 3 but is rank 2 for 'model_1_1/bidirectional_1/Tile' (op: 'Tile') with input shapes: [?,300,1], [2]."
     ]
    }
   ],
   "source": [
    "# combine to predict\n",
    "combined_sequence_input = Input(shape=(max_length,), dtype='int32')\n",
    "combined_embedded_sequences = embedding_layer(combined_sequence_input)\n",
    "combined_conc = concatenate([model_1(combined_embedded_sequences),\n",
    "             model_2(combined_embedded_sequences),\n",
    "             model_3(combined_embedded_sequences),\n",
    "             model_4(combined_embedded_sequences),\n",
    "             model_5(combined_embedded_sequences),\n",
    "             model_6(combined_embedded_sequences),])\n",
    "combined_model = Model(combined_sequence_input, combined_conc)\n",
    "combined_model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc'])    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = combined_model.predict(x_test, batch_size=4, verbose=1)\n",
    "submission = pd.read_csv('../submissions/sample_submission.csv')\n",
    "submission[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = y_pred\n",
    "submission.to_csv('bd_lstm_per_class1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_names = [0, 1]\n",
    "# cnf_matrix = confusion_matrix(y_test.values[:, 3], np.round(model_pred))\n",
    "# np.set_printoptions(precision=2)\n",
    "\n",
    "# # Plot non-normalized confusion matrix\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "#                       title='Confusion matrix, without normalization')\n",
    "\n",
    "# # Plot normalized confusion matrix\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "#                       title='Normalized confusion matrix')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "# with open(\"../ling_src/obscene_words.txt\", \"r\") as f:\n",
    "#     content = f.readlines()\n",
    "# swear_words = set([x.strip() for x in content])\n",
    "# print('Number of swear words in vocabulary: ', len(swear_words))\n",
    "\n",
    "# manual_pred_threat = []\n",
    "# for text in data['comment_text'].values:\n",
    "#     if any(word in text.lower() for word in swear_words) and 'will' in text.lower():\n",
    "#         manual_pred_threat.append(1)\n",
    "#     else:\n",
    "#         manual_pred_threat.append(0)\n",
    "\n",
    "# roc_auc_score(data['threat'].values, manual_pred_threat)\n",
    "\n",
    "# class_names = [0, 1]\n",
    "# cnf_matrix = confusion_matrix(data['threat'].values, manual_pred_threat)\n",
    "# np.set_printoptions(precision=2)\n",
    "\n",
    "# # Plot non-normalized confusion matrix\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "#                       title='Confusion matrix, without normalization')\n",
    "\n",
    "# # Plot normalized confusion matrix\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "#                       title='Normalized confusion matrix')\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
