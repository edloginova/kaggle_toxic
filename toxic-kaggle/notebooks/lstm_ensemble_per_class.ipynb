{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import logging\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.optimizers import Adam\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import itertools\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.utils import class_weight\n",
    "from keras.callbacks import *\n",
    "import gensim\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"../models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'lstm_ensemble_per_class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/\"\n",
    "data = pd.read_csv(DATA_PATH + \"preprocessed/train_heavy_clean_no-stopwords.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>heavy_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>' aww ! matches background colour seemingly st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man , really trying edit war . guy constan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\" cannotmake real suggestions improvement - wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>, sir , hero . chance remember page ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                id  \\\n",
       "0           0  0000997932d777bf   \n",
       "1           1  000103f0d9cfb60f   \n",
       "2           2  000113f07ec002fd   \n",
       "3           3  0001b41b1c6bb37e   \n",
       "4           4  0001d958c54c6e35   \n",
       "\n",
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0             0   \n",
       "1  D'aww! He matches this background colour I'm s...      0             0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0             0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0             0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \\\n",
       "0        0       0       0              0   \n",
       "1        0       0       0              0   \n",
       "2        0       0       0              0   \n",
       "3        0       0       0              0   \n",
       "4        0       0       0              0   \n",
       "\n",
       "                                         heavy_clean  \n",
       "0  explanation edits made username hardcore metal...  \n",
       "1  ' aww ! matches background colour seemingly st...  \n",
       "2  hey man , really trying edit war . guy constan...  \n",
       "3  \" cannotmake real suggestions improvement - wo...  \n",
       "4              , sir , hero . chance remember page ?  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[['comment_text', 'heavy_clean']], data[list_classes], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=None, oov_token=0)\n",
    "tokenizer.fit_on_texts(X_train['comment_text'])\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.loc[pd.isnull(X_train['heavy_clean'])]['heavy_clean'] = X_train[pd.isnull(X_train['heavy_clean'])]['comment_text'].apply(heavy_clean)\n",
    "\n",
    "# X_train.loc[8846]['heavy_clean'] = heavy_clean(X_train.loc[8846]['comment_text'])\n",
    "\n",
    "# X_train[pd.isnull(X_train['heavy_clean'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index_w2v = gensim.models.KeyedVectors.load_word2vec_format('../../../embeddings/GoogleNews-vectors-negative300.bin', binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print('Found %s word vectors.' % len(embeddings_index_w2v.vocab))\n",
    "embedding_matrix = np.zeros((len(word_index) + 2, 300))\n",
    "oov = []\n",
    "embedding_matrix[0] = np.random.rand(1, 300)\n",
    "embedding_matrix[-1] = np.zeros((1, 300))\n",
    "for word, i in word_index.items():\n",
    "    word = str(word)\n",
    "    if word in embeddings_index_w2v.vocab:\n",
    "        embedding_vector = embeddings_index_w2v[word]\n",
    "        embedding_matrix[i] = embedding_vector / np.linalg.norm(embedding_vector)\n",
    "    elif word.lower() in embeddings_index_w2v.vocab:\n",
    "        embedding_vector = embeddings_index_w2v[word.lower()]\n",
    "        embedding_matrix[i] = embedding_vector / np.linalg.norm(embedding_vector)\n",
    "    elif word.capitalize() in embeddings_index_w2v.vocab:\n",
    "        embedding_vector = embeddings_index_w2v[word.capitalize()]\n",
    "        embedding_matrix[i] = embedding_vector / np.linalg.norm(embedding_vector)\n",
    "    elif word.lower().capitalize() in embeddings_index_w2v.vocab:\n",
    "        embedding_vector = embeddings_index_w2v[word.lower().capitalize()]\n",
    "        embedding_matrix[i] = embedding_vector / np.linalg.norm(embedding_vector)\n",
    "    else:\n",
    "        oov.append(word)\n",
    "embedding_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164436"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58515"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(word_index) & set(embeddings_index_w2v.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80765"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.67564296,  0.82336147,  0.4424945 , ...,  0.7808966 ,\n",
       "         0.51950882,  0.89298894],\n",
       "       [ 0.07468531,  0.09791063,  0.04645062, ...,  0.00341549,\n",
       "         0.04440133, -0.06421115],\n",
       "       [ 0.01803273,  0.0796839 ,  0.03568782, ...,  0.03077838,\n",
       "        -0.01652214, -0.09403456],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.04803049, -0.03817808,  0.03217427, ...,  0.00434891,\n",
       "        -0.0180884 ,  0.08744012],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(embedding_matrix.shape[0],\n",
    "                            embedding_size,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_length, trainable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(clipnorm=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_texts = tokenizer.texts_to_sequences(X_train['comment_text'])\n",
    "x_train_texts = pad_sequences(x_train_texts, maxlen=max_length, padding='post')\n",
    "\n",
    "x_test_texts = tokenizer.texts_to_sequences(X_test['comment_text'])\n",
    "x_test_texts = pad_sequences(x_test_texts, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5527967652868119, 1: 5.235138576045441}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train.values[:, 0]), y_train.values[:, 0])\n",
    "class_weights = {i:x for i, x in enumerate(list(class_weights))}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 300)          49331400  \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 200, 20)           25760     \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_2 (CuDNNLSTM)     (None, 5)                 540       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 49,357,706\n",
      "Trainable params: 26,306\n",
      "Non-trainable params: 49,331,400\n",
      "_________________________________________________________________\n",
      "Train on 106912 samples, validate on 52659 samples\n",
      "Epoch 1/5\n",
      "106912/106912 [==============================] - 594s 6ms/step - loss: 0.3083 - acc: 0.8464 - val_loss: 0.2170 - val_acc: 0.9074\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.970488 \n",
      "\n",
      "Epoch 2/5\n",
      "106912/106912 [==============================] - 892s 8ms/step - loss: 0.2049 - acc: 0.9156 - val_loss: 0.1432 - val_acc: 0.9451\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.975447 \n",
      "\n",
      "Epoch 3/5\n",
      "106912/106912 [==============================] - 880s 8ms/step - loss: 0.1849 - acc: 0.9222 - val_loss: 0.1474 - val_acc: 0.9402\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.975306 \n",
      "\n",
      "Epoch 4/5\n",
      "106912/106912 [==============================] - 830s 8ms/step - loss: 0.1734 - acc: 0.9262 - val_loss: 0.1727 - val_acc: 0.9285\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.976710 \n",
      "\n",
      "Epoch 5/5\n",
      "106912/106912 [==============================] - 949s 9ms/step - loss: 0.1612 - acc: 0.9285 - val_loss: 0.1981 - val_acc: 0.9170\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.976522 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbe77e75e80>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_input = Input(shape=(max_length,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "lstm1 = CuDNNLSTM(20, return_sequences=True)(embedded_sequences)\n",
    "lstm2 = CuDNNLSTM(5)(lstm1)\n",
    "output = Dense(units=1, activation='sigmoid')(lstm2)\n",
    "model_1 = Model(sequence_input, output)\n",
    "model_1.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])    \n",
    "model_1.summary()\n",
    "RocAuc = RocAucEvaluation(validation_data=(x_test_texts, y_test), interval=1)\n",
    "model_1.fit(x_train_texts, y_train.values[:, 0], validation_data=(x_test_texts, y_test.values[:, 0]),\n",
    "              epochs=5, batch_size=5, callbacks=[RocAuc], class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.505049932447115, 1: 50.005612722170255}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train.values[:, 1]), y_train.values[:, 1])\n",
    "class_weights = {i:x for i, x in enumerate(list(class_weights))}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 300)          49331400  \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_3 (CuDNNLSTM)     (None, 200, 20)           25760     \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_4 (CuDNNLSTM)     (None, 5)                 540       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 49,357,706\n",
      "Trainable params: 26,306\n",
      "Non-trainable params: 49,331,400\n",
      "_________________________________________________________________\n",
      "Train on 106912 samples, validate on 52659 samples\n",
      "Epoch 1/5\n",
      "106912/106912 [==============================] - 938s 9ms/step - loss: 0.3651 - acc: 0.8323 - val_loss: 0.1546 - val_acc: 0.9624\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.918514 \n",
      "\n",
      "Epoch 2/5\n",
      "106912/106912 [==============================] - 935s 9ms/step - loss: 0.1614 - acc: 0.9461 - val_loss: 0.1136 - val_acc: 0.9612\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.867761 \n",
      "\n",
      "Epoch 3/5\n",
      "106912/106912 [==============================] - 945s 9ms/step - loss: 0.1392 - acc: 0.9467 - val_loss: 0.2612 - val_acc: 0.9066\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.926739 \n",
      "\n",
      "Epoch 4/5\n",
      "106912/106912 [==============================] - 921s 9ms/step - loss: 0.1209 - acc: 0.9533 - val_loss: 0.1233 - val_acc: 0.9514\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.869608 \n",
      "\n",
      "Epoch 5/5\n",
      "106912/106912 [==============================] - 710s 7ms/step - loss: 0.1084 - acc: 0.9603 - val_loss: 0.0951 - val_acc: 0.9699\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.866696 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbe772f7b70>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_input = Input(shape=(max_length,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "lstm1 = CuDNNLSTM(20, return_sequences=True)(embedded_sequences)\n",
    "lstm2 = CuDNNLSTM(5)(lstm1)\n",
    "output = Dense(units=1, activation='sigmoid')(lstm2)\n",
    "model_2 = Model(sequence_input, output)\n",
    "model_2.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])    \n",
    "model_2.summary()\n",
    "RocAuc = RocAucEvaluation(validation_data=(x_test_texts, y_test), interval=1)\n",
    "model_2.fit(x_train_texts, y_train.values[:, 1], validation_data=(x_test_texts, y_test.values[:, 1]),\n",
    "              epochs=5, batch_size=5, callbacks=[RocAuc], class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5277311588050625, 1: 9.515129939480243}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train.values[:, 2]), y_train.values[:, 2])\n",
    "class_weights = {i:x for i, x in enumerate(list(class_weights))}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 300)          49331400  \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_5 (CuDNNLSTM)     (None, 200, 20)           25760     \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_6 (CuDNNLSTM)     (None, 5)                 540       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 49,357,706\n",
      "Trainable params: 26,306\n",
      "Non-trainable params: 49,331,400\n",
      "_________________________________________________________________\n",
      "Train on 106912 samples, validate on 52659 samples\n",
      "Epoch 1/5\n",
      "106912/106912 [==============================] - 737s 7ms/step - loss: 0.3272 - acc: 0.8633 - val_loss: 0.1517 - val_acc: 0.9503\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.946982 \n",
      "\n",
      "Epoch 2/5\n",
      "106912/106912 [==============================] - 695s 6ms/step - loss: 0.1472 - acc: 0.9486 - val_loss: 0.1084 - val_acc: 0.9603\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.957607 \n",
      "\n",
      "Epoch 3/5\n",
      "106912/106912 [==============================] - 694s 6ms/step - loss: 0.1304 - acc: 0.9531 - val_loss: 0.1194 - val_acc: 0.9565\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.959419 \n",
      "\n",
      "Epoch 4/5\n",
      "106912/106912 [==============================] - 693s 6ms/step - loss: 0.1173 - acc: 0.9546 - val_loss: 0.1049 - val_acc: 0.9598\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.956746 \n",
      "\n",
      "Epoch 5/5\n",
      "106912/106912 [==============================] - 684s 6ms/step - loss: 0.1080 - acc: 0.9572 - val_loss: 0.0903 - val_acc: 0.9651\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.945308 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbe70c47e48>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_input = Input(shape=(max_length,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "lstm1 = CuDNNLSTM(20, return_sequences=True)(embedded_sequences)\n",
    "lstm2 = CuDNNLSTM(5)(lstm1)\n",
    "output = Dense(units=1, activation='sigmoid')(lstm2)\n",
    "model_3 = Model(sequence_input, output)\n",
    "model_3.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])    \n",
    "model_3.summary()\n",
    "RocAuc = RocAucEvaluation(validation_data=(x_test_texts, y_test), interval=1)\n",
    "model_3.fit(x_train_texts, y_train.values[:, 2], validation_data=(x_test_texts, y_test.values[:, 2]),\n",
    "              epochs=5, batch_size=5, callbacks=[RocAuc], class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5015292815191489, 1: 163.9754601226994}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train.values[:, 3]), y_train.values[:, 3])\n",
    "class_weights = {i:x for i, x in enumerate(list(class_weights))}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 300)          49331400  \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_7 (CuDNNLSTM)     (None, 200, 20)           25760     \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_8 (CuDNNLSTM)     (None, 5)                 540       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 49,357,706\n",
      "Trainable params: 26,306\n",
      "Non-trainable params: 49,331,400\n",
      "_________________________________________________________________\n",
      "Train on 106912 samples, validate on 52659 samples\n",
      "Epoch 1/1\n",
      "106912/106912 [==============================] - 688s 6ms/step - loss: 0.7037 - acc: 0.8021 - val_loss: 0.4862 - val_acc: 0.9815\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.631148 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbe4b8fc630>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_input = Input(shape=(max_length,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "lstm1 = CuDNNLSTM(20, return_sequences=True)(embedded_sequences)\n",
    "lstm2 = CuDNNLSTM(5)(lstm1)\n",
    "output = Dense(units=1, activation='sigmoid')(lstm2)\n",
    "model_4 = Model(sequence_input, output)\n",
    "model_4.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])    \n",
    "model_4.summary()\n",
    "RocAuc = RocAucEvaluation(validation_data=(x_test_texts, y_test), interval=1)\n",
    "model_4.fit(x_train_texts, y_train.values[:, 3], validation_data=(x_test_texts, y_test.values[:, 3]),\n",
    "              epochs=1, batch_size=5, callbacks=[RocAuc], class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5257381144397018, 1: 10.213221245701185}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train.values[:, 4]), y_train.values[:, 4])\n",
    "class_weights = {i:x for i, x in enumerate(list(class_weights))}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 300)          49331400  \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_9 (CuDNNLSTM)     (None, 200, 20)           25760     \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_10 (CuDNNLSTM)    (None, 5)                 540       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 49,357,706\n",
      "Trainable params: 26,306\n",
      "Non-trainable params: 49,331,400\n",
      "_________________________________________________________________\n",
      "Train on 106912 samples, validate on 52659 samples\n",
      "Epoch 1/5\n",
      "106912/106912 [==============================] - 687s 6ms/step - loss: 0.2992 - acc: 0.8738 - val_loss: 0.2157 - val_acc: 0.9133\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.960368 \n",
      "\n",
      "Epoch 2/5\n",
      "106912/106912 [==============================] - 689s 6ms/step - loss: 0.1783 - acc: 0.9238 - val_loss: 0.2090 - val_acc: 0.9173\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.956781 \n",
      "\n",
      "Epoch 3/5\n",
      "106912/106912 [==============================] - 687s 6ms/step - loss: 0.1611 - acc: 0.9298 - val_loss: 0.2457 - val_acc: 0.9038\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.967404 \n",
      "\n",
      "Epoch 4/5\n",
      "106912/106912 [==============================] - 683s 6ms/step - loss: 0.1483 - acc: 0.9358 - val_loss: 0.2159 - val_acc: 0.9139\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.967256 \n",
      "\n",
      "Epoch 5/5\n",
      "106912/106912 [==============================] - 685s 6ms/step - loss: 0.1379 - acc: 0.9378 - val_loss: 0.1674 - val_acc: 0.9301\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.966860 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbe4b794da0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_input = Input(shape=(max_length,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "lstm1 = CuDNNLSTM(20, return_sequences=True)(embedded_sequences)\n",
    "lstm2 = CuDNNLSTM(5)(lstm1)\n",
    "output = Dense(units=1, activation='sigmoid')(lstm2)\n",
    "model = Model(sequence_input, output)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])    \n",
    "model.summary()\n",
    "RocAuc = RocAucEvaluation(validation_data=(x_test_texts, y_test), interval=1)\n",
    "model.fit(x_train_texts, y_train.values[:, 4], validation_data=(x_test_texts, y_test.values[:, 4]),\n",
    "              epochs=5, batch_size=5, callbacks=[RocAuc], class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5044065749495178, 1: 57.23340471092077}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train.values[:, 5]), y_train.values[:, 5])\n",
    "class_weights = {i:x for i, x in enumerate(list(class_weights))}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 300)          49331400  \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_11 (CuDNNLSTM)    (None, 200, 20)           25760     \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_12 (CuDNNLSTM)    (None, 5)                 540       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 49,357,706\n",
      "Trainable params: 26,306\n",
      "Non-trainable params: 49,331,400\n",
      "_________________________________________________________________\n",
      "Train on 106912 samples, validate on 52659 samples\n",
      "Epoch 1/5\n",
      "106912/106912 [==============================] - 686s 6ms/step - loss: 0.6104 - acc: 0.5943 - val_loss: 0.2631 - val_acc: 0.9366\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.870074 \n",
      "\n",
      "Epoch 2/5\n",
      "106912/106912 [==============================] - 688s 6ms/step - loss: 0.2716 - acc: 0.8900 - val_loss: 0.3890 - val_acc: 0.8361\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.911871 \n",
      "\n",
      "Epoch 3/5\n",
      "106912/106912 [==============================] - 685s 6ms/step - loss: 0.2020 - acc: 0.9222 - val_loss: 0.1560 - val_acc: 0.9419\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.874362 \n",
      "\n",
      "Epoch 4/5\n",
      "106912/106912 [==============================] - 687s 6ms/step - loss: 0.1778 - acc: 0.9360 - val_loss: 0.1700 - val_acc: 0.9353\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.882016 \n",
      "\n",
      "Epoch 5/5\n",
      "106912/106912 [==============================] - 684s 6ms/step - loss: 0.1571 - acc: 0.9405 - val_loss: 0.1403 - val_acc: 0.9509\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.892984 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbe4b56ff60>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_input = Input(shape=(max_length,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "lstm1 = CuDNNLSTM(20, return_sequences=True)(embedded_sequences)\n",
    "lstm2 = CuDNNLSTM(5)(lstm1)\n",
    "output = Dense(units=1, activation='sigmoid')(lstm2)\n",
    "model_5 = Model(sequence_input, output)\n",
    "model_5.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])    \n",
    "model_5.summary()\n",
    "RocAuc = RocAucEvaluation(validation_data=(x_test_texts, y_test), interval=1)\n",
    "model_5.fit(x_train_texts, y_train.values[:, 5], validation_data=(x_test_texts, y_test.values[:, 5]),\n",
    "              epochs=5, batch_size=5, callbacks=[RocAuc], class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model_1.to_json()\n",
    "with open(\"../models/lstm_ensemble_per_class_model_1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_1.save_weights(\"../models/lstm_ensemble_per_class_model_1.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " \n",
    "\n",
    "model_json = model_2.to_json()\n",
    "with open(\"../models/lstm_ensemble_per_class_model_2.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_2.save_weights(\"../models/lstm_ensemble_per_class_model_2.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " \n",
    "\n",
    "model_json = model_3.to_json()\n",
    "with open(\"../models/lstm_ensemble_per_class_model_3.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_3.save_weights(\"../models/lstm_ensemble_per_class_model_3.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " \n",
    "\n",
    "model_json = model_4.to_json()\n",
    "with open(\"../models/lstm_ensemble_per_class_model_4.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_4.save_weights(\"../models/lstm_ensemble_per_class_model_4.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " \n",
    "\n",
    "# model_json = model_5.to_json()\n",
    "with open(\"../models/lstm_ensemble_per_class_model_5.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_5.save_weights(\"../models/lstm_ensemble_per_class_model_5.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_names = [0, 1]\n",
    "# cnf_matrix = confusion_matrix(y_test.values[:, 3], np.round(model_pred))\n",
    "# np.set_printoptions(precision=2)\n",
    "\n",
    "# # Plot non-normalized confusion matrix\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "#                       title='Confusion matrix, without normalization')\n",
    "\n",
    "# # Plot normalized confusion matrix\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "#                       title='Normalized confusion matrix')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "# with open(\"../ling_src/obscene_words.txt\", \"r\") as f:\n",
    "#     content = f.readlines()\n",
    "# swear_words = set([x.strip() for x in content])\n",
    "# print('Number of swear words in vocabulary: ', len(swear_words))\n",
    "\n",
    "# manual_pred_threat = []\n",
    "# for text in data['comment_text'].values:\n",
    "#     if any(word in text.lower() for word in swear_words) and 'will' in text.lower():\n",
    "#         manual_pred_threat.append(1)\n",
    "#     else:\n",
    "#         manual_pred_threat.append(0)\n",
    "\n",
    "# roc_auc_score(data['threat'].values, manual_pred_threat)\n",
    "\n",
    "# class_names = [0, 1]\n",
    "# cnf_matrix = confusion_matrix(data['threat'].values, manual_pred_threat)\n",
    "# np.set_printoptions(precision=2)\n",
    "\n",
    "# # Plot non-normalized confusion matrix\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "#                       title='Confusion matrix, without normalization')\n",
    "\n",
    "# # Plot normalized confusion matrix\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "#                       title='Normalized confusion matrix')\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
