{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import logging\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.optimizers import Adam\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import itertools\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.utils import class_weight\n",
    "from keras.callbacks import *\n",
    "import gensim\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"../models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bidirectional_lstm_ensemble_per_class_maskzero'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/\"\n",
    "data = pd.read_csv(DATA_PATH + \"preprocessed/train_heavy_clean_no-stopwords.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>heavy_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>' aww ! matches background colour seemingly st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man , really trying edit war . guy constan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\" cannotmake real suggestions improvement - wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>, sir , hero . chance remember page ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                id  \\\n",
       "0           0  0000997932d777bf   \n",
       "1           1  000103f0d9cfb60f   \n",
       "2           2  000113f07ec002fd   \n",
       "3           3  0001b41b1c6bb37e   \n",
       "4           4  0001d958c54c6e35   \n",
       "\n",
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0             0   \n",
       "1  D'aww! He matches this background colour I'm s...      0             0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0             0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0             0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \\\n",
       "0        0       0       0              0   \n",
       "1        0       0       0              0   \n",
       "2        0       0       0              0   \n",
       "3        0       0       0              0   \n",
       "4        0       0       0              0   \n",
       "\n",
       "                                         heavy_clean  \n",
       "0  explanation edits made username hardcore metal...  \n",
       "1  ' aww ! matches background colour seemingly st...  \n",
       "2  hey man , really trying edit war . guy constan...  \n",
       "3  \" cannotmake real suggestions improvement - wo...  \n",
       "4              , sir , hero . chance remember page ?  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[['comment_text', 'heavy_clean']], data[list_classes], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=None, oov_token=0)\n",
    "tokenizer.fit_on_texts(X_train['comment_text'])\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.loc[pd.isnull(X_train['heavy_clean'])]['heavy_clean'] = X_train[pd.isnull(X_train['heavy_clean'])]['comment_text'].apply(heavy_clean)\n",
    "\n",
    "# X_train.loc[8846]['heavy_clean'] = heavy_clean(X_train.loc[8846]['comment_text'])\n",
    "\n",
    "# X_train[pd.isnull(X_train['heavy_clean'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index_w2v = gensim.models.KeyedVectors.load_word2vec_format('../../../embeddings/GoogleNews-vectors-negative300.bin', binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print('Found %s word vectors.' % len(embeddings_index_w2v.vocab))\n",
    "embedding_matrix = np.zeros((len(word_index) + 2, 300))\n",
    "oov = []\n",
    "embedding_matrix[0] = np.random.rand(1, 300)\n",
    "embedding_matrix[-1] = np.zeros((1, 300))\n",
    "for word, i in word_index.items():\n",
    "    word = str(word)\n",
    "    if word in embeddings_index_w2v.vocab:\n",
    "        embedding_vector = embeddings_index_w2v[word]\n",
    "        embedding_matrix[i] = embedding_vector / np.linalg.norm(embedding_vector)\n",
    "    elif word.lower() in embeddings_index_w2v.vocab:\n",
    "        embedding_vector = embeddings_index_w2v[word.lower()]\n",
    "        embedding_matrix[i] = embedding_vector / np.linalg.norm(embedding_vector)\n",
    "    elif word.capitalize() in embeddings_index_w2v.vocab:\n",
    "        embedding_vector = embeddings_index_w2v[word.capitalize()]\n",
    "        embedding_matrix[i] = embedding_vector / np.linalg.norm(embedding_vector)\n",
    "    elif word.lower().capitalize() in embeddings_index_w2v.vocab:\n",
    "        embedding_vector = embeddings_index_w2v[word.lower().capitalize()]\n",
    "        embedding_matrix[i] = embedding_vector / np.linalg.norm(embedding_vector)\n",
    "    else:\n",
    "        oov.append(word)\n",
    "embedding_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164436"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58515"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(word_index) & set(embeddings_index_w2v.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80765"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24379435,  0.03723172,  0.57753296, ...,  0.66281788,\n",
       "         0.48706424,  0.28950906],\n",
       "       [ 0.07468531,  0.09791063,  0.04645062, ...,  0.00341549,\n",
       "         0.04440133, -0.06421115],\n",
       "       [ 0.01803273,  0.0796839 ,  0.03568782, ...,  0.03077838,\n",
       "        -0.01652214, -0.09403456],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.04803049, -0.03817808,  0.03217427, ...,  0.00434891,\n",
       "        -0.0180884 ,  0.08744012],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(embedding_matrix.shape[0],\n",
    "                            embedding_size,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_length, trainable = False, mask_zero = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(clipnorm=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_texts = tokenizer.texts_to_sequences(X_train['comment_text'])\n",
    "x_train_texts = pad_sequences(x_train_texts, maxlen=max_length, padding='post')\n",
    "\n",
    "x_test_texts = tokenizer.texts_to_sequences(X_test['comment_text'])\n",
    "x_test_texts = pad_sequences(x_test_texts, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5527967652868119, 1: 5.235138576045441}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train.values[:, 0]), y_train.values[:, 0])\n",
    "class_weights = {i:x for i, x in enumerate(list(class_weights))}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 300)          49331400  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 200, 20)           25680     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 5)                 520       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 49,357,606\n",
      "Trainable params: 26,206\n",
      "Non-trainable params: 49,331,400\n",
      "_________________________________________________________________\n",
      "Train on 106912 samples, validate on 52659 samples\n",
      "Epoch 1/5\n",
      "106912/106912 [==============================] - 39047s 365ms/step - loss: 0.2808 - acc: 0.8927 - val_loss: 0.2411 - val_acc: 0.9098\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.969775 \n",
      "\n",
      "Epoch 2/5\n",
      "106912/106912 [==============================] - 21760s 204ms/step - loss: 0.2054 - acc: 0.9173 - val_loss: 0.1413 - val_acc: 0.9466\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.972276 \n",
      "\n",
      "Epoch 3/5\n",
      "106912/106912 [==============================] - 21758s 204ms/step - loss: 0.1858 - acc: 0.9219 - val_loss: 0.1853 - val_acc: 0.9275\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.976465 \n",
      "\n",
      "Epoch 4/5\n",
      "106912/106912 [==============================] - 20756s 194ms/step - loss: 0.1724 - acc: 0.9279 - val_loss: 0.1740 - val_acc: 0.9302\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.976541 \n",
      "\n",
      "Epoch 5/5\n",
      "106912/106912 [==============================] - 20321s 190ms/step - loss: 0.1585 - acc: 0.9311 - val_loss: 0.1852 - val_acc: 0.9306\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.976952 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6012e25da0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_input = Input(shape=(max_length,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "lstm1 = LSTM(20, return_sequences=True)(embedded_sequences)\n",
    "lstm2 = LSTM(5)(lstm1)\n",
    "output = Dense(units=1, activation='sigmoid')(lstm2)\n",
    "model_1 = Model(sequence_input, output)\n",
    "model_1.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])    \n",
    "model_1.summary()\n",
    "RocAuc = RocAucEvaluation(validation_data=(x_test_texts, y_test), interval=1)\n",
    "model_1.fit(x_train_texts, y_train.values[:, 0], validation_data=(x_test_texts, y_test.values[:, 0]),\n",
    "              epochs=5, batch_size=5, callbacks=[RocAuc], class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.505049932447115, 1: 50.005612722170255}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train.values[:, 1]), y_train.values[:, 1])\n",
    "class_weights = {i:x for i, x in enumerate(list(class_weights))}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 300)          49331400  \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 200, 20)           25680     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 5)                 520       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 49,357,606\n",
      "Trainable params: 26,206\n",
      "Non-trainable params: 49,331,400\n",
      "_________________________________________________________________\n",
      "Train on 106912 samples, validate on 52659 samples\n",
      "Epoch 1/5\n",
      "106912/106912 [==============================] - 20416s 191ms/step - loss: 0.2686 - acc: 0.9213 - val_loss: 0.1396 - val_acc: 0.9566\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.890030 \n",
      "\n",
      "Epoch 2/5\n",
      "106912/106912 [==============================] - 22494s 210ms/step - loss: 0.1508 - acc: 0.9452 - val_loss: 0.1510 - val_acc: 0.9423\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.849468 \n",
      "\n",
      "Epoch 3/5\n",
      "106912/106912 [==============================] - 26638s 249ms/step - loss: 0.1362 - acc: 0.9507 - val_loss: 0.0887 - val_acc: 0.9683\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.872204 \n",
      "\n",
      "Epoch 4/5\n",
      "106912/106912 [==============================] - 20053s 188ms/step - loss: 0.1282 - acc: 0.9547 - val_loss: 0.1466 - val_acc: 0.9549\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.922265 \n",
      "\n",
      "Epoch 5/5\n",
      "106912/106912 [==============================] - 20051s 188ms/step - loss: 0.1109 - acc: 0.9565 - val_loss: 0.1943 - val_acc: 0.9357\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.898695 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f601018b908>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_input = Input(shape=(max_length,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "lstm1 = LSTM(20, return_sequences=True)(embedded_sequences)\n",
    "lstm2 = LSTM(5)(lstm1)\n",
    "output = Dense(units=1, activation='sigmoid')(lstm2)\n",
    "model_2 = Model(sequence_input, output)\n",
    "model_2.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])    \n",
    "model_2.summary()\n",
    "RocAuc = RocAucEvaluation(validation_data=(x_test_texts, y_test), interval=1)\n",
    "model_2.fit(x_train_texts, y_train.values[:, 1], validation_data=(x_test_texts, y_test.values[:, 1]),\n",
    "              epochs=5, batch_size=5, callbacks=[RocAuc], class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5277311588050625, 1: 9.515129939480243}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train.values[:, 2]), y_train.values[:, 2])\n",
    "class_weights = {i:x for i, x in enumerate(list(class_weights))}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 300)          49331400  \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 200, 20)           25680     \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 5)                 520       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 49,357,606\n",
      "Trainable params: 26,206\n",
      "Non-trainable params: 49,331,400\n",
      "_________________________________________________________________\n",
      "Train on 106912 samples, validate on 52659 samples\n",
      "Epoch 1/5\n",
      "106912/106912 [==============================] - 28463s 266ms/step - loss: 0.2267 - acc: 0.9231 - val_loss: 0.2071 - val_acc: 0.9288\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.955587 \n",
      "\n",
      "Epoch 2/5\n",
      "106912/106912 [==============================] - 23768s 222ms/step - loss: 0.1447 - acc: 0.9507 - val_loss: 0.1912 - val_acc: 0.9296\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.962189 \n",
      "\n",
      "Epoch 3/5\n",
      "106912/106912 [==============================] - 20060s 188ms/step - loss: 0.1269 - acc: 0.9554 - val_loss: 0.1616 - val_acc: 0.9435\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.961879 \n",
      "\n",
      "Epoch 4/5\n",
      " 67955/106912 [==================>...........] - ETA: 2:13:46 - loss: 0.1143 - acc: 0.9565"
     ]
    }
   ],
   "source": [
    "sequence_input = Input(shape=(max_length,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "lstm1 = LSTM(20, return_sequences=True)(embedded_sequences)\n",
    "lstm2 = LSTM(5)(lstm1)\n",
    "output = Dense(units=1, activation='sigmoid')(lstm2)\n",
    "model_3 = Model(sequence_input, output)\n",
    "model_3.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])    \n",
    "model_3.summary()\n",
    "RocAuc = RocAucEvaluation(validation_data=(x_test_texts, y_test), interval=1)\n",
    "model_3.fit(x_train_texts, y_train.values[:, 2], validation_data=(x_test_texts, y_test.values[:, 2]),\n",
    "              epochs=5, batch_size=5, callbacks=[RocAuc], class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train.values[:, 3]), y_train.values[:, 3])\n",
    "class_weights = {i:x for i, x in enumerate(list(class_weights))}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(max_length,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "lstm1 = LSTM(20, return_sequences=True)(embedded_sequences)\n",
    "lstm2 = LSTM(5)(lstm1)\n",
    "output = Dense(units=1, activation='sigmoid')(lstm2)\n",
    "model_4 = Model(sequence_input, output)\n",
    "model_4.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])    \n",
    "model_4.summary()\n",
    "RocAuc = RocAucEvaluation(validation_data=(x_test_texts, y_test), interval=1)\n",
    "model_4.fit(x_train_texts, y_train.values[:, 3], validation_data=(x_test_texts, y_test.values[:, 3]),\n",
    "              epochs=1, batch_size=5, callbacks=[RocAuc], class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train.values[:, 4]), y_train.values[:, 4])\n",
    "class_weights = {i:x for i, x in enumerate(list(class_weights))}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(max_length,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "lstm1 = LSTM(20, return_sequences=True)(embedded_sequences)\n",
    "lstm2 = LSTM(5)(lstm1)\n",
    "output = Dense(units=1, activation='sigmoid')(lstm2)\n",
    "model = Model(sequence_input, output)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])    \n",
    "model.summary()\n",
    "RocAuc = RocAucEvaluation(validation_data=(x_test_texts, y_test), interval=1)\n",
    "model.fit(x_train_texts, y_train.values[:, 4], validation_data=(x_test_texts, y_test.values[:, 4]),\n",
    "              epochs=5, batch_size=5, callbacks=[RocAuc], class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train.values[:, 5]), y_train.values[:, 5])\n",
    "class_weights = {i:x for i, x in enumerate(list(class_weights))}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(max_length,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "lstm1 = LSTM(20, return_sequences=True)(embedded_sequences)\n",
    "lstm2 = LSTM(5)(lstm1)\n",
    "output = Dense(units=1, activation='sigmoid')(lstm2)\n",
    "model_5 = Model(sequence_input, output)\n",
    "model_5.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])    \n",
    "model_5.summary()\n",
    "RocAuc = RocAucEvaluation(validation_data=(x_test_texts, y_test), interval=1)\n",
    "model_5.fit(x_train_texts, y_train.values[:, 5], validation_data=(x_test_texts, y_test.values[:, 5]),\n",
    "              epochs=5, batch_size=5, callbacks=[RocAuc], class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_names = [0, 1]\n",
    "# cnf_matrix = confusion_matrix(y_test.values[:, 3], np.round(model_pred))\n",
    "# np.set_printoptions(precision=2)\n",
    "\n",
    "# # Plot non-normalized confusion matrix\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "#                       title='Confusion matrix, without normalization')\n",
    "\n",
    "# # Plot normalized confusion matrix\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "#                       title='Normalized confusion matrix')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "# with open(\"../ling_src/obscene_words.txt\", \"r\") as f:\n",
    "#     content = f.readlines()\n",
    "# swear_words = set([x.strip() for x in content])\n",
    "# print('Number of swear words in vocabulary: ', len(swear_words))\n",
    "\n",
    "# manual_pred_threat = []\n",
    "# for text in data['comment_text'].values:\n",
    "#     if any(word in text.lower() for word in swear_words) and 'will' in text.lower():\n",
    "#         manual_pred_threat.append(1)\n",
    "#     else:\n",
    "#         manual_pred_threat.append(0)\n",
    "\n",
    "# roc_auc_score(data['threat'].values, manual_pred_threat)\n",
    "\n",
    "# class_names = [0, 1]\n",
    "# cnf_matrix = confusion_matrix(data['threat'].values, manual_pred_threat)\n",
    "# np.set_printoptions(precision=2)\n",
    "\n",
    "# # Plot non-normalized confusion matrix\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "#                       title='Confusion matrix, without normalization')\n",
    "\n",
    "# # Plot normalized confusion matrix\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "#                       title='Normalized confusion matrix')\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
