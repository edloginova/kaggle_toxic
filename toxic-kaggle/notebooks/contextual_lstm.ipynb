{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.optimizers import Adam\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.utils import class_weight\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, Activation, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"../models/\"\n",
    "DATA_PATH = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_PATH + \"preprocessed/train_ling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_features = ['count_sent', 'count_word', 'count_unique_word', 'count_letters',\n",
    "       'count_punctuations', 'count_words_upper', 'count_words_title',\n",
    "       'count_stopwords', 'mean_word_len', 'word_unique_percent',\n",
    "       'punct_percent', 'count_swear_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>count_sent</th>\n",
       "      <th>...</th>\n",
       "      <th>count_unique_word</th>\n",
       "      <th>count_letters</th>\n",
       "      <th>count_punctuations</th>\n",
       "      <th>count_words_upper</th>\n",
       "      <th>count_words_title</th>\n",
       "      <th>count_stopwords</th>\n",
       "      <th>mean_word_len</th>\n",
       "      <th>word_unique_percent</th>\n",
       "      <th>punct_percent</th>\n",
       "      <th>count_swear_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>264</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>5.162791</td>\n",
       "      <td>95.348837</td>\n",
       "      <td>23.255814</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>112</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5.588235</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>70.588235</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>233</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>92.857143</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>622</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>55</td>\n",
       "      <td>4.486726</td>\n",
       "      <td>72.566372</td>\n",
       "      <td>18.584071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4.230769</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>38.461538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                id  \\\n",
       "0           0  0000997932d777bf   \n",
       "1           1  000103f0d9cfb60f   \n",
       "2           2  000113f07ec002fd   \n",
       "3           3  0001b41b1c6bb37e   \n",
       "4           4  0001d958c54c6e35   \n",
       "\n",
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0             0   \n",
       "1  D'aww! He matches this background colour I'm s...      0             0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0             0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0             0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  count_sent        ...          \\\n",
       "0        0       0       0              0           2        ...           \n",
       "1        0       0       0              0           1        ...           \n",
       "2        0       0       0              0           1        ...           \n",
       "3        0       0       0              0           5        ...           \n",
       "4        0       0       0              0           1        ...           \n",
       "\n",
       "   count_unique_word  count_letters  count_punctuations  count_words_upper  \\\n",
       "0                 41            264                  10                  2   \n",
       "1                 17            112                  12                  1   \n",
       "2                 39            233                   6                  0   \n",
       "3                 82            622                  21                  5   \n",
       "4                 13             67                   5                  0   \n",
       "\n",
       "   count_words_title  count_stopwords  mean_word_len  word_unique_percent  \\\n",
       "0                 11               16       5.162791            95.348837   \n",
       "1                  3                2       5.588235           100.000000   \n",
       "2                  2               19       4.571429            92.857143   \n",
       "3                  7               55       4.486726            72.566372   \n",
       "4                  2                5       4.230769           100.000000   \n",
       "\n",
       "   punct_percent  count_swear_words  \n",
       "0      23.255814                  0  \n",
       "1      70.588235                  0  \n",
       "2      14.285714                  0  \n",
       "3      18.584071                  0  \n",
       "4      38.461538                  0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_input_data(sentences, labels, vocabulary):\n",
    "    x = np.array([[embeddings_index[vocabulary_inv[vocabulary['word']]] if word in vocabulary.keys() else len(vocabulary) - 1 for word in sentence] for sentence in sentences])\n",
    "    y = np.array(labels)\n",
    "    return [x, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=18400)\n",
    "tokenizer.fit_on_texts(train_text)\n",
    "sequences = tokenizer.texts_to_sequences(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = tokenizer.word_index\n",
    "vocabulary_inv = {v:k for k, v in vocabulary.items()}\n",
    "embeddings_index = {}\n",
    "EMBEDDING_DIM = 100\n",
    "f = open(\"../../../embeddings/glove.6B.\" + str(EMBEDDING_DIM) + \"d.txt\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "embedding_matrix = np.zeros((len(vocabulary) + 1, EMBEDDING_DIM))\n",
    "embedding_matrix[-1] = np.random.rand(EMBEDDING_DIM) # oov-vector\n",
    "for word, i in vocabulary.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i - 1] = embedding_vector\n",
    "embedding_layer = Embedding(embedding_matrix.shape[0],\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=200, trainable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_dev, y_train, y_dev = train_test_split(train, targets, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 200\n",
    "\n",
    "x_train_texts = tokenizer.texts_to_sequences(x_train['comment_text'])\n",
    "x_train_texts = pad_sequences(x_train_texts, maxlen=max_length, padding='post')\n",
    "\n",
    "x_dev_texts = tokenizer.texts_to_sequences(x_dev['comment_text'])\n",
    "x_dev_texts = pad_sequences(x_dev_texts, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 200, 100)     21033800    input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_3 (CuDNNLSTM)        (None, 10)           4480        embedding_1[3][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 22)           0           cu_dnnlstm_3[0][0]               \n",
      "                                                                 input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 50)           1150        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output_1 (Dense)                (None, 1)            51          dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output_2 (Dense)                (None, 1)            51          dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output_3 (Dense)                (None, 1)            51          dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output_4 (Dense)                (None, 1)            51          dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output_5 (Dense)                (None, 1)            51          dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output_6 (Dense)                (None, 1)            51          dense_14[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 21,039,736\n",
      "Trainable params: 5,936\n",
      "Non-trainable params: 21,033,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sequence_input = Input(shape=(max_length,), dtype='float32')\n",
    "metadata_input = Input(shape=(len(meta_features),), dtype='float32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "lstm = keras.layers.CuDNNLSTM(10, return_sequences=False)(embedded_sequences)\n",
    "concatenated_data = Concatenate(axis=1)([lstm, metadata_input])\n",
    "dense_1 = Dense(50, activation='relu')(concatenated_data)\n",
    "# dense_2 = Dense(1, activation='relu')(dense_1)\n",
    "output_1 = Dense(units=1, activation='sigmoid', name = 'output_1')(dense_1)\n",
    "output_2 = Dense(units=1, activation='sigmoid', name = 'output_2')(dense_1)\n",
    "output_3 = Dense(units=1, activation='sigmoid', name = 'output_3')(dense_1)\n",
    "output_4 = Dense(units=1, activation='sigmoid', name = 'output_4')(dense_1)\n",
    "output_5 = Dense(units=1, activation='sigmoid', name = 'output_5')(dense_1)\n",
    "output_6 = Dense(units=1, activation='sigmoid', name = 'output_6')(dense_1)\n",
    "model = Model(inputs=[sequence_input,metadata_input], outputs=[output_1, output_2, output_3, output_4, output_5, output_6])\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "separate_targets_train = [y_train[:, i] for i in range(0, y_train.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "separate_targets_dev = [y_dev[:, i] for i in range(0, y_dev.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "separate_class_weights = [class_weight.compute_class_weight('balanced', np.unique(separate_targets_train[i]),separate_targets_train[i]) for i in range(0, len(separate_targets_train))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "separate_class_weights_dict = [{0:x[0], 1: x[1]} for x in separate_class_weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: 0.5530365294542862, 1: 5.213732262882749},\n",
       " {0: 0.5050140157337915, 1: 50.360234445446345},\n",
       " {0: 0.527848137156683, 1: 9.477261157305277},\n",
       " {0: 0.5015356017134083, 1: 163.30263157894737},\n",
       " {0: 0.5258353654517893, 1: 10.176658163265307},\n",
       " {0: 0.5043937286635478, 1: 57.39928057553957}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "separate_class_weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.55303653, 5.21373226]),\n",
       " array([ 0.50501402, 50.36023445]),\n",
       " array([0.52784814, 9.47726116]),\n",
       " array([  0.5015356 , 163.30263158]),\n",
       " array([ 0.52583537, 10.17665816]),\n",
       " array([ 0.50439373, 57.39928058])]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "separate_class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_class_weights = {'output_' + str(i + 1): x for i, x in enumerate(separate_class_weights_dict)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "separate_targets_train_ = [y_train[i, :] for i in range(0, y_train.shape[0])]\n",
    "separate_targets_dev_ = [y_dev[i, :] for i in range(0, y_dev.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111699"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 111699 samples, validate on 47872 samples\n",
      "Epoch 1/20\n",
      "111699/111699 [==============================] - 248s 2ms/step - loss: 14.6250 - output_1_loss: 1.0940 - output_2_loss: 1.7121 - output_3_loss: 0.7244 - output_4_loss: 3.2788 - output_5_loss: 0.9288 - output_6_loss: 6.8868 - output_1_acc: 0.6669 - output_2_acc: 0.7830 - output_3_acc: 0.7540 - output_4_acc: 0.5305 - output_5_acc: 0.6616 - output_6_acc: 0.9197 - val_loss: 7.2398 - val_output_1_loss: 0.2458 - val_output_2_loss: 0.2900 - val_output_3_loss: 0.4268 - val_output_4_loss: 1.1107 - val_output_5_loss: 0.6827 - val_output_6_loss: 4.4838 - val_output_1_acc: 0.9337 - val_output_2_acc: 0.9375 - val_output_3_acc: 0.9059 - val_output_4_acc: 0.5603 - val_output_5_acc: 0.6470 - val_output_6_acc: 0.2757\n",
      "Epoch 2/20\n",
      "111699/111699 [==============================] - 226s 2ms/step - loss: 5.2862 - output_1_loss: 0.6634 - output_2_loss: 0.5935 - output_3_loss: 0.6256 - output_4_loss: 1.5382 - output_5_loss: 0.6322 - output_6_loss: 1.2333 - output_1_acc: 0.7605 - output_2_acc: 0.8744 - output_3_acc: 0.8320 - output_4_acc: 0.6851 - output_5_acc: 0.7940 - output_6_acc: 0.7090 - val_loss: 2.2673 - val_output_1_loss: 0.6242 - val_output_2_loss: 0.3251 - val_output_3_loss: 0.4089 - val_output_4_loss: 0.1273 - val_output_5_loss: 0.5149 - val_output_6_loss: 0.2668 - val_output_1_acc: 0.7487 - val_output_2_acc: 0.9175 - val_output_3_acc: 0.9181 - val_output_4_acc: 0.9727 - val_output_5_acc: 0.8402 - val_output_6_acc: 0.912781 - output_5_loss: 0.7104 - output_6_loss: 1.9006 - output_1_acc: 0.7316 - output_2_acc: 0.8584 - out - ETA: 25s - loss: 5.3964 - output_1_loss: 0.6725 - output_2_loss: 0.6106 - output_3_loss: 0.6259 - output_4_lo - ETA: 18s - loss: 5.4579 - output_1_loss: 0.6702 - output_2_loss: 0.6155 - output_3_loss: 0.6327 - output_4_loss: 1.6488 - output_5_loss: 0.6379 - output_6_loss: 1.2528 - output_1_acc: 0.7568 - output_2_acc: 0.87\n",
      "Epoch 3/20\n",
      "111699/111699 [==============================] - 225s 2ms/step - loss: 4.4930 - output_1_loss: 0.6186 - output_2_loss: 0.5606 - output_3_loss: 0.5103 - output_4_loss: 1.2285 - output_5_loss: 0.6139 - output_6_loss: 0.9611 - output_1_acc: 0.7857 - output_2_acc: 0.8917 - output_3_acc: 0.8727 - output_4_acc: 0.7304 - output_5_acc: 0.8186 - output_6_acc: 0.7700 - val_loss: 11.4798 - val_output_1_loss: 0.3731 - val_output_2_loss: 0.1613 - val_output_3_loss: 0.3015 - val_output_4_loss: 10.1098 - val_output_5_loss: 0.2875 - val_output_6_loss: 0.2466 - val_output_1_acc: 0.9075 - val_output_2_acc: 0.9688 - val_output_3_acc: 0.9368 - val_output_4_acc: 0.1221 - val_output_5_acc: 0.9337 - val_output_6_acc: 0.9390\n",
      "Epoch 4/20\n",
      "111699/111699 [==============================] - 226s 2ms/step - loss: 4.1129 - output_1_loss: 0.5596 - output_2_loss: 0.3916 - output_3_loss: 0.4797 - output_4_loss: 1.2628 - output_5_loss: 0.5365 - output_6_loss: 0.8828 - output_1_acc: 0.8076 - output_2_acc: 0.9059 - output_3_acc: 0.8698 - output_4_acc: 0.7295 - output_5_acc: 0.8362 - output_6_acc: 0.7949 - val_loss: 3.9464 - val_output_1_loss: 0.9583 - val_output_2_loss: 0.2536 - val_output_3_loss: 1.3896 - val_output_4_loss: 0.3146 - val_output_5_loss: 0.5222 - val_output_6_loss: 0.5082 - val_output_1_acc: 0.4565 - val_output_2_acc: 0.9414 - val_output_3_acc: 0.2605 - val_output_4_acc: 0.9347 - val_output_5_acc: 0.8420 - val_output_6_acc: 0.7934 output_6_loss: 1.4225 - output_1_acc: 0.8242 - output_2_acc: 0.9055 - output_3_acc: 0.8779 - output_4_acc: 0.7993 - output_5_acc: 0.8507 - output_6_acc:  - ETA: 2:31 - loss: 4.3839 - output_1_loss: 0.5368 - output_2_loss: 0.4231 - output_3_loss: 0.4591 - output_4_loss: 1.0322 - output_5_loss: 0.5238 - output_6_loss: 1.4088 - output_1_acc: 0.8249 - output_2_acc: 0.9060 - output_3_acc: 0.8787 - output_4_acc: 0. - ETA: 2:27 - loss: 4.2878 - output_1_loss: 0.5399 - output_2_loss: 0.4078 - output_3_loss: 0.4512 - output_4_loss: 1.0059 - output_5_loss: 0.5242 - output_6_loss: 1.3589 - output_1_acc: 0.8215 - output_2_acc: 0.9063 - output_3_acc: 0.8805 - output_4_acc: 0.801 - ETA: 2:24 - loss: 4.3661 - output_1_loss: 0.5640 - output_2_loss: 0.3963 - output_3_loss: 0.4728 - output_4_loss: 1.0926 - output - - ETA: 21s - loss: 4.2516 - output_1_loss: 0.5626 - output_2_loss: 0.3927 - output_3_loss: 0.4851 - output_4_loss: 1.3393 - output_5_loss: 0.5400 - output_6_loss: 0.9318 - output_1_acc: 0.8064 - output_2_acc: 0.9051 - output_3_acc: 0.8671 - output_4_acc: 0.7206 - output_5_acc: 0.8335  - ETA: 21s - loss: 4.2500 - output_1_loss:  - ETA: 11s - loss: 4.1764 - output_1_loss: 0.5614 - output_2_loss: 0.3913 - output_3_loss: 0.4806 - output_4_loss: 1.3010 - output_5_loss: 0.5371 - output_6_loss: 0.9051 - output_ - ETA: 5s - loss: 4.1453 - output_1_loss: 0.5590 - output_2_loss: 0.3893 - output_3_loss: 0.4790 - output_4_loss: 1.2854 - output_5_loss: 0.5354 - output_6_loss: 0.8971 - output_1_acc: 0.8075 - output_2_acc: 0.9050 - output_3_acc: 0\n",
      "Epoch 5/20\n",
      "111699/111699 [==============================] - 226s 2ms/step - loss: 3.2343 - output_1_loss: 0.5291 - output_2_loss: 0.3220 - output_3_loss: 0.4398 - output_4_loss: 0.8041 - output_5_loss: 0.4965 - output_6_loss: 0.6428 - output_1_acc: 0.8171 - output_2_acc: 0.9224 - output_3_acc: 0.8688 - output_4_acc: 0.8061 - output_5_acc: 0.8477 - output_6_acc: 0.8397 - val_loss: 2.1558 - val_output_1_loss: 0.5051 - val_output_2_loss: 0.3773 - val_output_3_loss: 0.3375 - val_output_4_loss: 0.2210 - val_output_5_loss: 0.4342 - val_output_6_loss: 0.2806 - val_output_1_acc: 0.7611 - val_output_2_acc: 0.9103 - val_output_3_acc: 0.8811 - val_output_4_acc: 0.9468 - val_output_5_acc: 0.8436 - val_output_6_acc: 0.9254cc: 0.8682 - output_4_acc: 0.\n",
      "Epoch 6/20\n",
      "111699/111699 [==============================] - 227s 2ms/step - loss: 2.6292 - output_1_loss: 0.4683 - output_2_loss: 0.3186 - output_3_loss: 0.3929 - output_4_loss: 0.5119 - output_5_loss: 0.4226 - output_6_loss: 0.5149 - output_1_acc: 0.8332 - output_2_acc: 0.9202 - output_3_acc: 0.8787 - output_4_acc: 0.8536 - output_5_acc: 0.8584 - output_6_acc: 0.8546 - val_loss: 1.4973 - val_output_1_loss: 0.2572 - val_output_2_loss: 0.2263 - val_output_3_loss: 0.1914 - val_output_4_loss: 0.2740 - val_output_5_loss: 0.1949 - val_output_6_loss: 0.3535 - val_output_1_acc: 0.9190 - val_output_2_acc: 0.9483 - val_output_3_acc: 0.9479 - val_output_4_acc: 0.9341 - val_output_5_acc: 0.9492 - val_output_6_acc: 0.9110\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111699/111699 [==============================] - 225s 2ms/step - loss: 2.2849 - output_1_loss: 0.4240 - output_2_loss: 0.2408 - output_3_loss: 0.3581 - output_4_loss: 0.4636 - output_5_loss: 0.3636 - output_6_loss: 0.4349 - output_1_acc: 0.8442 - output_2_acc: 0.9248 - output_3_acc: 0.8873 - output_4_acc: 0.8739 - output_5_acc: 0.8797 - output_6_acc: 0.8716 - val_loss: 2.2260 - val_output_1_loss: 0.4586 - val_output_2_loss: 0.2445 - val_output_3_loss: 0.3426 - val_output_4_loss: 0.2780 - val_output_5_loss: 0.3837 - val_output_6_loss: 0.5186 - val_output_1_acc: 0.7935 - val_output_2_acc: 0.9213 - val_output_3_acc: 0.8733 - val_output_4_acc: 0.9032 - val_output_5_acc: 0.8540 - val_output_6_acc: 0.8014.9215 - output_3_acc: 0 - ETA: 1:30 - loss: 2.3356 - output_1_loss: 0.4338 - output_2_loss: 0.2635 - output_3_loss: 0.3754 - output_4_loss: 0.4655 - output_5_loss: 0.3753 - output_6_loss: 0.4220 - output_1_acc: 0.8384 - output_2_acc: 0.9227 - output_3_acc: 0.8832 - output_4_acc: 0.8681 - output_5_ac - ETA: 1:28 - loss: 2.3628 - output_1_loss: 0.4331 - output_2_loss: 0.2601 - output_3_loss: 0.3726 - output_4_loss: 0.5046 - output_5_loss: 0.3734 - output_6_loss: 0.4189 - output_1_acc: 0.8388 - output_2_acc: 0.9234 - output_3_acc: 0.8838 - ETA: 1:23 - loss: 2.3654 - output_1_loss: 0.4349 - output_2_loss: 0.2558 - output_3_loss: 0.3736 - output_4_loss: 0.4965 - output_5_loss: 0.3769 - output_6_loss: 0.4276 - output_1_acc: 0.8380 - output_2_acc: 0.9242 - output_3_acc: 0.8832 - output_4_acc: 0.8681 - output_5_acc: 0.8728 -  - ETA: 1:22 - loss: 2.3618 - output_1_loss: 0.4336 - output_2_loss: 0.2541 - output_3_loss: 0.3747 - output_4_loss: 0.4973 - output_5_loss: 0.3762 - output_6_loss: 0.4260 - output - ETA: 13s - loss: 2.3247 - output_1_loss: 0.4274 - output_2_loss:\n",
      "Epoch 8/20\n",
      "111699/111699 [==============================] - 226s 2ms/step - loss: 2.0727 - output_1_loss: 0.4016 - output_2_loss: 0.2062 - output_3_loss: 0.3236 - output_4_loss: 0.4466 - output_5_loss: 0.3400 - output_6_loss: 0.3547 - output_1_acc: 0.8514 - output_2_acc: 0.9291 - output_3_acc: 0.8906 - output_4_acc: 0.8829 - output_5_acc: 0.8828 - output_6_acc: 0.8812 - val_loss: 2.2760 - val_output_1_loss: 0.4194 - val_output_2_loss: 0.2989 - val_output_3_loss: 0.3810 - val_output_4_loss: 0.4238 - val_output_5_loss: 0.3766 - val_output_6_loss: 0.3764 - val_output_1_acc: 0.8191 - val_output_2_acc: 0.8995 - val_output_3_acc: 0.8512 - val_output_4_acc: 0.8555 - val_output_5_acc: 0.8544 - val_output_6_acc: 0.8652put_3_acc: 0.8865 - output_4_acc: 0.8639 - ETA: 2:34 - loss: 2.3962 - output_1_loss: 0.3996 - output_2_loss: 0.2229 - output_3_loss: 0.3173 - output_4_loss: 0.7281 - output_5_loss: 0.3259 - outp - ETA: 2:23 - loss: 2.2661 - output_1_loss: 0.3950 - output_2_loss: 0.2185 - output_3_loss: 0.3169 - output_4_loss: 0.6271 - output_5_loss: 0.3259 - output_6_loss: 0.3827 - output_1_acc: 0.8468 - output_2_acc: 0.9271 - output_3_acc: 0.891 - ETA: 2:18 - loss: 2.2123 - output_1_loss: 0.3935 - output_2_loss: 0.2166 - output_3_loss: 0.3148 - output_4 - ETA: 2:04 - loss: 2.1664 - output_1_loss: 0.3989 - output_2_loss: 0.2128 - output_3_loss: 0.3158 - output_4_loss: 0.5274 - output_5_loss: 0.3318 - outp - ETA: 1:32 - loss: 2.2003 - output_1_loss: 0.3972 - output_2_loss: 0.1990 - output_3_loss: 0.3154 - output_4_loss: 0.5817 - output_5_loss: 0.3311 - output - ETA: 28s - loss: 2.0915 - output_1_loss: 0.4023 - output_2_loss: 0.2005 - output_3_loss: 0.3230 - output_4_loss: 0.4764 - output_5_loss: 0.3405 - output_6_loss - ETA: 23s - loss: 2.0800 - output_1_loss: 0.4031 - output_2_loss: 0.1986 - output_3_loss: 0.3212 - output_4_loss: 0.4689 - output_5_loss: 0.3400 - output_6_loss: 0.3481 - output_1_acc: 0.8499 - output_2_acc: 0.9277 - output_3_acc: 0.8893 - output_4_acc: 0.8806 - output_5_acc: - ETA: 22s - loss: 2.0774 - output_1_loss: 0.4028 - output_2_loss: 0.1986 - output_3_loss: 0.3219 - - ETA: 14s - loss: 2.0639 - output_1_loss: 0.4011 - output_2_loss: 0.1950 - output_3_loss: 0.3205 - output_4_loss: 0.4611 - output_5_loss: 0.3385 - output_6_loss: 0.3476 - output_1_acc: 0.8 - ETA: 10s - loss: 2.0598 - output_1_loss: 0.4012 - output_2_loss: 0.1972 - output_3_loss: 0.3202 - output_4_loss: 0.4551 - output_5_loss: 0.3378 - output_6_loss: 0.348 - ETA: 2s - loss: 2.0734 - output_1_loss: 0.4016 - output_2_loss: 0.2047 - output_3_loss: 0.3223 - output_4_loss: 0.4492 - output_5_loss: 0.3406 - output_6_loss: 0.3551 - output_1_acc: 0.8513 - output_2_acc: 0.9293 - output_3_acc: 0.8906 - output_4_acc: 0.8833 - output_5_acc:  - ETA: 0s - loss: 2.0722 - output_1_loss: 0.4016 - output_2_loss: 0.2062 - output_3_loss: 0.3236 - output_4_loss: 0.4467 - output_5_loss: 0.3400 - output_6_loss: 0.3540 - output_1_acc: 0.8515 - output_2_acc: 0.9291 - output_3_acc: 0.8906 - output_4_acc: 0.8829 - output_5_acc: 0.8829 - output_6_acc: 0.88\n",
      "Epoch 9/20\n",
      "111699/111699 [==============================] - 226s 2ms/step - loss: 1.8979 - output_1_loss: 0.3889 - output_2_loss: 0.1831 - output_3_loss: 0.3148 - output_4_loss: 0.3426 - output_5_loss: 0.3257 - output_6_loss: 0.3428 - output_1_acc: 0.8591 - output_2_acc: 0.9269 - output_3_acc: 0.8925 - output_4_acc: 0.8929 - output_5_acc: 0.8862 - output_6_acc: 0.8798 - val_loss: 2.1197 - val_output_1_loss: 0.4006 - val_output_2_loss: 0.2671 - val_output_3_loss: 0.3065 - val_output_4_loss: 0.3663 - val_output_5_loss: 0.3765 - val_output_6_loss: 0.4027 - val_output_1_acc: 0.8337 - val_output_2_acc: 0.9025 - val_output_3_acc: 0.8826 - val_output_4_acc: 0.8706 - val_output_5_acc: 0.8528 - val_output_6_acc: 0.84514026 - output_2_loss: 0.1911 - output_3 - ETA: 1:23 - loss: 1.9279 - output_1_loss: 0.3997 - output_2_loss: 0.1827 - output_3_loss: 0.3165 - output_4_loss: 0.3618 - output_5_loss: 0.3344 - output_6_loss: 0.3329 - output_1_acc: 0.8571 - output_2_acc: 0.9260 - output_3_acc: 0.8922 - output_4_acc: 0.8935 - output_5_acc - ETA: 1:21 - loss: 1.9304 - output_1_loss: 0.4000 - output_2_loss: 0.1838 - output_3_loss: 0.3170 - output_4_loss: 0.3613 - output_5_loss: 0.3349 - output_6_loss: 0.3335 - outp - ETA: 12s - loss: 1.8929 - output_1_loss: 0.3902 - output_2_loss: 0.1788 - output\n",
      "Epoch 10/20\n",
      "111699/111699 [==============================] - 188s 2ms/step - loss: 1.7903 - output_1_loss: 0.3880 - output_2_loss: 0.1744 - output_3_loss: 0.3087 - output_4_loss: 0.2720 - output_5_loss: 0.3227 - output_6_loss: 0.3244 - output_1_acc: 0.8588 - output_2_acc: 0.9264 - output_3_acc: 0.8899 - output_4_acc: 0.8942 - output_5_acc: 0.8839 - output_6_acc: 0.8778 - val_loss: 2.1671 - val_output_1_loss: 0.4320 - val_output_2_loss: 0.2694 - val_output_3_loss: 0.3651 - val_output_4_loss: 0.3755 - val_output_5_loss: 0.4236 - val_output_6_loss: 0.3015 - val_output_1_acc: 0.8164 - val_output_2_acc: 0.9048 - val_output_3_acc: 0.8536 - val_output_4_acc: 0.8641 - val_output_5_acc: 0.8255 - val_output_6_acc: 0.8872\n",
      "Epoch 11/20\n",
      "111699/111699 [==============================] - 177s 2ms/step - loss: 1.8026 - output_1_loss: 0.3767 - output_2_loss: 0.1674 - output_3_loss: 0.2993 - output_4_loss: 0.3306 - output_5_loss: 0.3126 - output_6_loss: 0.3161 - output_1_acc: 0.8644 - output_2_acc: 0.9326 - output_3_acc: 0.8953 - output_4_acc: 0.8969 - output_5_acc: 0.8886 - output_6_acc: 0.8827 - val_loss: 1.4447 - val_output_1_loss: 0.2899 - val_output_2_loss: 0.1432 - val_output_3_loss: 0.2158 - val_output_4_loss: 0.2822 - val_output_5_loss: 0.2298 - val_output_6_loss: 0.2839 - val_output_1_acc: 0.9057 - val_output_2_acc: 0.9476 - val_output_3_acc: 0.9305 - val_output_4_acc: 0.9025 - val_output_5_acc: 0.9245 - val_output_6_acc: 0.9033\n",
      "Epoch 12/20\n",
      "111699/111699 [==============================] - 177s 2ms/step - loss: 1.7072 - output_1_loss: 0.3664 - output_2_loss: 0.1515 - output_3_loss: 0.2884 - output_4_loss: 0.2912 - output_5_loss: 0.3015 - output_6_loss: 0.3082 - output_1_acc: 0.8649 - output_2_acc: 0.9334 - output_3_acc: 0.8934 - output_4_acc: 0.9032 - output_5_acc: 0.8891 - output_6_acc: 0.8829 - val_loss: 1.3852 - val_output_1_loss: 0.2972 - val_output_2_loss: 0.1325 - val_output_3_loss: 0.2535 - val_output_4_loss: 0.1489 - val_output_5_loss: 0.2722 - val_output_6_loss: 0.2809 - val_output_1_acc: 0.8955 - val_output_2_acc: 0.9406 - val_output_3_acc: 0.9089 - val_output_4_acc: 0.9315 - val_output_5_acc: 0.9030 - val_output_6_acc: 0.8974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "111699/111699 [==============================] - 181s 2ms/step - loss: 1.6602 - output_1_loss: 0.3616 - output_2_loss: 0.1577 - output_3_loss: 0.2795 - output_4_loss: 0.2680 - output_5_loss: 0.2912 - output_6_loss: 0.3022 - output_1_acc: 0.8710 - output_2_acc: 0.9311 - output_3_acc: 0.8999 - output_4_acc: 0.9037 - output_5_acc: 0.8923 - output_6_acc: 0.8819 - val_loss: 1.5889 - val_output_1_loss: 0.3317 - val_output_2_loss: 0.1516 - val_output_3_loss: 0.2284 - val_output_4_loss: 0.2212 - val_output_5_loss: 0.3240 - val_output_6_loss: 0.3319 - val_output_1_acc: 0.8745 - val_output_2_acc: 0.9406 - val_output_3_acc: 0.9177 - val_output_4_acc: 0.9121 - val_output_5_acc: 0.8847 - val_output_6_acc: 0.8843\n",
      "Epoch 14/20\n",
      "111699/111699 [==============================] - 195s 2ms/step - loss: 1.6293 - output_1_loss: 0.3578 - output_2_loss: 0.1563 - output_3_loss: 0.2746 - output_4_loss: 0.2677 - output_5_loss: 0.2827 - output_6_loss: 0.2902 - output_1_acc: 0.8704 - output_2_acc: 0.9332 - output_3_acc: 0.9006 - output_4_acc: 0.9097 - output_5_acc: 0.8951 - output_6_acc: 0.8905 - val_loss: 1.5576 - val_output_1_loss: 0.3098 - val_output_2_loss: 0.1908 - val_output_3_loss: 0.2467 - val_output_4_loss: 0.2304 - val_output_5_loss: 0.2635 - val_output_6_loss: 0.3164 - val_output_1_acc: 0.8767 - val_output_2_acc: 0.9249 - val_output_3_acc: 0.9039 - val_output_4_acc: 0.9072 - val_output_5_acc: 0.8984 - val_output_6_acc: 0.8797\n",
      "Epoch 15/20\n",
      "111699/111699 [==============================] - 177s 2ms/step - loss: 1.6657 - output_1_loss: 0.3564 - output_2_loss: 0.1485 - output_3_loss: 0.2724 - output_4_loss: 0.3261 - output_5_loss: 0.2800 - output_6_loss: 0.2824 - output_1_acc: 0.8715 - output_2_acc: 0.9314 - output_3_acc: 0.8994 - output_4_acc: 0.9094 - output_5_acc: 0.8960 - output_6_acc: 0.8873 - val_loss: 1.8264 - val_output_1_loss: 0.3399 - val_output_2_loss: 0.2710 - val_output_3_loss: 0.3176 - val_output_4_loss: 0.3132 - val_output_5_loss: 0.2865 - val_output_6_loss: 0.2981 - val_output_1_acc: 0.8726 - val_output_2_acc: 0.9069 - val_output_3_acc: 0.8817 - val_output_4_acc: 0.8901 - val_output_5_acc: 0.8939 - val_output_6_acc: 0.8852\n",
      "Epoch 16/20\n",
      "111699/111699 [==============================] - 178s 2ms/step - loss: 1.7516 - output_1_loss: 0.3483 - output_2_loss: 0.1490 - output_3_loss: 0.2651 - output_4_loss: 0.4157 - output_5_loss: 0.2846 - output_6_loss: 0.2888 - output_1_acc: 0.8756 - output_2_acc: 0.9348 - output_3_acc: 0.9050 - output_4_acc: 0.9113 - output_5_acc: 0.8999 - output_6_acc: 0.8922 - val_loss: 1.5003 - val_output_1_loss: 0.3810 - val_output_2_loss: 0.1689 - val_output_3_loss: 0.2535 - val_output_4_loss: 0.1787 - val_output_5_loss: 0.2574 - val_output_6_loss: 0.2608 - val_output_1_acc: 0.8554 - val_output_2_acc: 0.9336 - val_output_3_acc: 0.9080 - val_output_4_acc: 0.9254 - val_output_5_acc: 0.9075 - val_output_6_acc: 0.9094\n",
      "Epoch 17/20\n",
      "111699/111699 [==============================] - 204s 2ms/step - loss: 1.7095 - output_1_loss: 0.3432 - output_2_loss: 0.1424 - output_3_loss: 0.2579 - output_4_loss: 0.4287 - output_5_loss: 0.2705 - output_6_loss: 0.2667 - output_1_acc: 0.8785 - output_2_acc: 0.9339 - output_3_acc: 0.9058 - output_4_acc: 0.9146 - output_5_acc: 0.9016 - output_6_acc: 0.8936 - val_loss: 1.5208 - val_output_1_loss: 0.3194 - val_output_2_loss: 0.1809 - val_output_3_loss: 0.2634 - val_output_4_loss: 0.2001 - val_output_5_loss: 0.2730 - val_output_6_loss: 0.2839 - val_output_1_acc: 0.8805 - val_output_2_acc: 0.9285 - val_output_3_acc: 0.9027 - val_output_4_acc: 0.9168 - val_output_5_acc: 0.8991 - val_output_6_acc: 0.8938\n",
      "Epoch 18/20\n",
      "111699/111699 [==============================] - 204s 2ms/step - loss: 1.6163 - output_1_loss: 0.3426 - output_2_loss: 0.1612 - output_3_loss: 0.2592 - output_4_loss: 0.3026 - output_5_loss: 0.2682 - output_6_loss: 0.2826 - output_1_acc: 0.8788 - output_2_acc: 0.9313 - output_3_acc: 0.9049 - output_4_acc: 0.9167 - output_5_acc: 0.9017 - output_6_acc: 0.8959 - val_loss: 1.6063 - val_output_1_loss: 0.3669 - val_output_2_loss: 0.2724 - val_output_3_loss: 0.2371 - val_output_4_loss: 0.2222 - val_output_5_loss: 0.2899 - val_output_6_loss: 0.2177 - val_output_1_acc: 0.8570 - val_output_2_acc: 0.9213 - val_output_3_acc: 0.9135 - val_output_4_acc: 0.9192 - val_output_5_acc: 0.8981 - val_output_6_acc: 0.9140.1526 - output_3_loss: 0.2554 - output_4_loss: 0.3007 - output_5_loss: 0\n",
      "Epoch 19/20\n",
      "111699/111699 [==============================] - 204s 2ms/step - loss: 1.4896 - output_1_loss: 0.3367 - output_2_loss: 0.1397 - output_3_loss: 0.2531 - output_4_loss: 0.2319 - output_5_loss: 0.2644 - output_6_loss: 0.2638 - output_1_acc: 0.8828 - output_2_acc: 0.9363 - output_3_acc: 0.9088 - output_4_acc: 0.9136 - output_5_acc: 0.9026 - output_6_acc: 0.8971 - val_loss: 1.5004 - val_output_1_loss: 0.3033 - val_output_2_loss: 0.1477 - val_output_3_loss: 0.2572 - val_output_4_loss: 0.2408 - val_output_5_loss: 0.2581 - val_output_6_loss: 0.2933 - val_output_1_acc: 0.8999 - val_output_2_acc: 0.9407 - val_output_3_acc: 0.9192 - val_output_4_acc: 0.9160 - val_output_5_acc: 0.9117 - val_output_6_acc: 0.8896\n",
      "Epoch 20/20\n",
      "111699/111699 [==============================] - 204s 2ms/step - loss: 1.4287 - output_1_loss: 0.3309 - output_2_loss: 0.1256 - output_3_loss: 0.2472 - output_4_loss: 0.2147 - output_5_loss: 0.2561 - output_6_loss: 0.2540 - output_1_acc: 0.8847 - output_2_acc: 0.9379 - output_3_acc: 0.9116 - output_4_acc: 0.9178 - output_5_acc: 0.9052 - output_6_acc: 0.8944 - val_loss: 1.3950 - val_output_1_loss: 0.3187 - val_output_2_loss: 0.1292 - val_output_3_loss: 0.2618 - val_output_4_loss: 0.1388 - val_output_5_loss: 0.2754 - val_output_6_loss: 0.2712 - val_output_1_acc: 0.8850 - val_output_2_acc: 0.9476 - val_output_3_acc: 0.9115 - val_output_4_acc: 0.9314 - val_output_5_acc: 0.9039 - val_output_6_acc: 0.9038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd4f7de8f98>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x_train_texts, x_train[meta_features]], separate_targets_train, validation_data=([x_dev_texts, x_dev[meta_features]], separate_targets_dev),\n",
    "          epochs=20, batch_size=20, class_weight = multiple_class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dev = model.predict([x_dev_texts, x_dev[meta_features]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_roc_auc(y_true, y_pred):\n",
    "    roc_auc_scores = []\n",
    "    for i in range(0, y_true.shape[1]):\n",
    "        roc_auc_scores.append(metrics.roc_auc_score(y_true[:, i], y_pred[:, i]))\n",
    "    print(roc_auc_scores)\n",
    "    return np.mean(roc_auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9276342117896024, 0.9751219474279966, 0.9553500442588447, 0.9423514378099153, 0.9494162589756695, 0.9451369859003185]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9491684810270579"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_roc_auc(y_dev, np.hstack(pred_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(MODEL_PATH + \"keras_contextual_lstm_classification_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(MODEL_PATH + \"keras_contextual_lstm_classification_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'keras_contextual_lstm_classification_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(DATA_PATH + \"preprocessed/test_ling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev_texts = tokenizer.texts_to_sequences(test['comment_text'])\n",
    "x_dev_texts = pad_sequences(x_dev_texts, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict([x_dev_texts, test[meta_features]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "sample_submission = pd.read_csv('../submissions/sample_submission.csv')\n",
    "sample_submission[list_classes] = np.hstack(pred)\n",
    "sample_submission.to_csv(\"../submissions/\" + model_name + \".csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
